"""
goalsniper ‚Äî FULL AI mode (in-play + prematch) with odds + EV gate.

- Pure ML (calibrated) loaded from Postgres settings (train_models.py).
- Markets: OU(2.5,3.5), BTTS (Yes/No), 1X2 (Draw suppressed).
- Adds bookmaker odds filtering + EV check.
- Scheduler: scan, results backfill, nightly train, daily digest, MOTD.

Safe to run on Railway/Render. Requires DATABASE_URL and API keys.
"""

import os, json, time, logging, requests, psycopg2
from psycopg2.pool import SimpleConnectionPool
from html import escape
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional, Tuple
from flask import Flask, jsonify, request, abort
from urllib3.util.retry import Retry
from requests.adapters import HTTPAdapter
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger

# Try zoneinfo import with fallback for compatibility
try:
    from zoneinfo import ZoneInfo
    TZ_UTC, BERLIN_TZ = ZoneInfo("UTC"), ZoneInfo("Europe/Berlin")
    log.info("üïê Using zoneinfo for timezones")
except ImportError:
    # Fallback for Python < 3.9
    from backports.zoneinfo import ZoneInfo
    TZ_UTC, BERLIN_TZ = ZoneInfo("UTC"), ZoneInfo("Europe/Berlin")
    log.info("üïê Using backports.zoneinfo for timezones")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ App / logging ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
logging.basicConfig(level=logging.INFO, format="[%(asctime)s] %(levelname)s - %(message)s")
log = logging.getLogger("goalsniper")
app = Flask(__name__)

log.info("üöÄ Starting goalsniper application")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Env bootstrap ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
log.info("üîß Loading environment variables")
try:
    from dotenv import load_dotenv
    load_dotenv()
    log.info("‚úÖ Environment variables loaded from .env file")
except Exception as e:
    log.info("‚ÑπÔ∏è No .env file found or error loading: %s", e)
    pass

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Core env ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
log.info("üìã Loading core environment variables")

# Validate required environment variables
REQUIRED_ENV_VARS = [
    "TELEGRAM_BOT_TOKEN",
    "TELEGRAM_CHAT_ID",
    "API_KEY",
    "ADMIN_API_KEY",
    "DATABASE_URL"
]

missing_vars = []
for var in REQUIRED_ENV_VARS:
    if not os.getenv(var):
        missing_vars.append(var)

if missing_vars:
    log.critical("‚ùå Missing required environment variables: %s", missing_vars)
    raise SystemExit(f"Missing required environment variables: {missing_vars}")

log.info("‚úÖ All required environment variables are present")

TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID   = os.getenv("TELEGRAM_CHAT_ID")
API_KEY            = os.getenv("API_KEY")
ADMIN_API_KEY      = os.getenv("ADMIN_API_KEY")
WEBHOOK_SECRET     = os.getenv("TELEGRAM_WEBHOOK_SECRET")
RUN_SCHEDULER      = os.getenv("RUN_SCHEDULER", "1") not in ("0","false","False","no","NO")

log.info("‚öôÔ∏è Loading configuration thresholds and limits")
CONF_THRESHOLD     = float(os.getenv("CONF_THRESHOLD", "70"))
MAX_TIPS_PER_SCAN  = int(os.getenv("MAX_TIPS_PER_SCAN", "25"))
DUP_COOLDOWN_MIN   = int(os.getenv("DUP_COOLDOWN_MIN", "20"))
TIP_MIN_MINUTE     = int(os.getenv("TIP_MIN_MINUTE", "8"))
SCAN_INTERVAL_SEC  = int(os.getenv("SCAN_INTERVAL_SEC", "300"))

HARVEST_MODE       = os.getenv("HARVEST_MODE", "1") not in ("0","false","False","no","NO")
TRAIN_ENABLE       = os.getenv("TRAIN_ENABLE", "1") not in ("0","false","False","no","NO")
TRAIN_HOUR_UTC     = int(os.getenv("TRAIN_HOUR_UTC", "2"))
TRAIN_MINUTE_UTC   = int(os.getenv("TRAIN_MINUTE_UTC", "12"))
TRAIN_MIN_MINUTE   = int(os.getenv("TRAIN_MIN_MINUTE", "15"))

BACKFILL_EVERY_MIN = int(os.getenv("BACKFILL_EVERY_MIN", "15"))
BACKFILL_DAYS      = int(os.getenv("BACKFILL_DAYS", "14"))
DAILY_ACCURACY_DIGEST_ENABLE = os.getenv("DAILY_ACCURACY_DIGEST_ENABLE", "1") not in ("0","false","False","no","NO")
DAILY_ACCURACY_HOUR   = int(os.getenv("DAILY_ACCURACY_HOUR", "3"))
DAILY_ACCURACY_MINUTE = int(os.getenv("DAILY_ACCURACY_MINUTE", "6"))

AUTO_TUNE_ENABLE        = os.getenv("AUTO_TUNE_ENABLE", "0") not in ("0","false","False","no","NO")
TARGET_PRECISION        = float(os.getenv("TARGET_PRECISION", "0.60"))
THRESH_MIN_PREDICTIONS  = int(os.getenv("THRESH_MIN_PREDICTIONS", "25"))
MIN_THRESH              = float(os.getenv("MIN_THRESH", "55"))
MAX_THRESH              = float(os.getenv("MAX_THRESH", "85"))

MOTD_PREMATCH_ENABLE    = os.getenv("MOTD_PREMATCH_ENABLE", "1") not in ("0","false","False","no","NO")
MOTD_PREDICT            = os.getenv("MOTD_PREDICT", "1") not in ("0","false","False","no","NO")
MOTD_HOUR               = int(os.getenv("MOTD_HOUR", "19"))
MOTD_MINUTE             = int(os.getenv("MOTD_MINUTE", "15"))
MOTD_CONF_MIN           = float(os.getenv("MOTD_CONF_MIN", "70"))
try:
    MOTD_LEAGUE_IDS = [int(x) for x in (os.getenv("MOTD_LEAGUE_IDS","").split(",")) if x.strip().isdigit()]
    log.info("üèÜ MOTD League IDs loaded: %s", MOTD_LEAGUE_IDS)
except Exception as e:
    log.warning("‚ö†Ô∏è Failed to parse MOTD_LEAGUE_IDS: %s", e)
    MOTD_LEAGUE_IDS = []

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Lines ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _parse_lines(env_val: str, default: List[float]) -> List[float]:
    log.debug("üìê Parsing lines from env value: %s", env_val)
    out=[]
    for t in (env_val or "").split(","):
        t=t.strip()
        if not t: continue
        try: out.append(float(t))
        except: pass
    result = out or default
    log.debug("üìê Parsed lines: %s (default: %s)", result, default)
    return result

log.info("üéØ Loading OU lines configuration")
OU_LINES = [ln for ln in _parse_lines(os.getenv("OU_LINES","2.5,3.5"), [2.5,3.5]) if abs(ln-1.5)>1e-6]
log.info("‚úÖ OU lines configured: %s", OU_LINES)

TOTAL_MATCH_MINUTES   = int(os.getenv("TOTAL_MATCH_MINUTES", "95"))
PREDICTIONS_PER_MATCH = int(os.getenv("PREDICTIONS_PER_MATCH", "2"))

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Odds/EV controls ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
log.info("üí∞ Loading odds and EV controls")
MIN_ODDS_OU   = float(os.getenv("MIN_ODDS_OU",   "1.30"))
MIN_ODDS_BTTS = float(os.getenv("MIN_ODDS_BTTS", "1.30"))
MIN_ODDS_1X2  = float(os.getenv("MIN_ODDS_1X2",  "1.30"))
MAX_ODDS_ALL  = float(os.getenv("MAX_ODDS_ALL",  "20.0"))
EDGE_MIN_BPS  = int(os.getenv("EDGE_MIN_BPS", "300"))  # 300 = +3.00%
ODDS_BOOKMAKER_ID = os.getenv("ODDS_BOOKMAKER_ID")  # optional API-Football book id
ALLOW_TIPS_WITHOUT_ODDS = os.getenv("ALLOW_TIPS_WITHOUT_ODDS","1") not in ("0","false","False","no","NO")

log.info("üìä Odds configuration: MIN_ODDS_OU=%.2f, MIN_ODDS_BTTS=%.2f, MIN_ODDS_1X2=%.2f, MAX_ODDS_ALL=%.2f", 
         MIN_ODDS_OU, MIN_ODDS_BTTS, MIN_ODDS_1X2, MAX_ODDS_ALL)
log.info("üìà EV configuration: EDGE_MIN_BPS=%d, ALLOW_TIPS_WITHOUT_ODDS=%s", EDGE_MIN_BPS, ALLOW_TIPS_WITHOUT_ODDS)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Markets allow-list (draw suppressed) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
log.info("üé≤ Building allowed suggestions list")
ALLOWED_SUGGESTIONS = {"BTTS: Yes", "BTTS: No", "OU 2.5", "OU 3.5", "Home Win", "Away Win"}
def _fmt_line(line: float) -> str: return f"{line}".rstrip("0").rstrip(".")
for _ln in OU_LINES:
    s=_fmt_line(_ln); ALLOWED_SUGGESTIONS.add(f"Over {s} Goals"); ALLOWED_SUGGESTIONS.add(f"Under {s} Goals")
log.info("‚úÖ Allowed suggestions: %s", sorted(list(ALLOWED_SUGGESTIONS)))

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ External APIs / HTTP session ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
DATABASE_URL = os.getenv("DATABASE_URL")
if not DATABASE_URL: 
    log.critical("‚ùå DATABASE_URL is required but not set")
    raise SystemExit("DATABASE_URL is required")
log.info("‚úÖ DATABASE_URL configured")

BASE_URL = "https://v3.football.api-sports.io"
FOOTBALL_API_URL = f"{BASE_URL}/fixtures"
TELEGRAM_API_URL = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}"
HEADERS = {"x-apisports-key": API_KEY, "Accept": "application/json"}
INPLAY_STATUSES = {"1H","HT","2H","ET","BT","P"}

session = requests.Session()
session.mount("https://", HTTPAdapter(max_retries=Retry(total=3, backoff_factor=1, status_forcelist=[429,500,502,503,504], respect_retry_after_header=True)))
log.info("üåê HTTP session configured with retry logic")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Caches & timezones ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
STATS_CACHE:  Dict[int, Tuple[float, list]] = {}
EVENTS_CACHE: Dict[int, Tuple[float, list]] = {}
ODDS_CACHE:   Dict[int, Tuple[float, dict]] = {}
SETTINGS_TTL = int(os.getenv("SETTINGS_TTL_SEC","60"))
MODELS_TTL   = int(os.getenv("MODELS_CACHE_TTL_SEC","120"))
log.info("üóÑÔ∏è Cache TTLs: SETTINGS_TTL=%ds, MODELS_TTL=%ds", SETTINGS_TTL, MODELS_TTL)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ TARGET LEAGUES FILTER ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
TARGET_LEAGUES = [
    "England Premier League",
    "England Championship",
    "Spain La Liga",
    "Spain La Liga 2",
    "Italy Serie A",
    "Italy Serie B",
    "Germany Bundesliga",
    "Germany 2. Bundesliga",
    "France Ligue 1",
    "France Ligue 2",
    "Belgium Pro League",
    "Portugal Primeira Liga",
    "Portugal Segunda Liga",
    "Brazil Serie A",
    "Brazil Serie B",
    "USA MLS",
    "Netherlands Eredivisie",
    "Argentina Liga Profesional",
    "Poland Ekstraklasa",
    "Japan J League",
    "Sweden Allsvenskan",
    "Croatia HNL",
    "Turkey Super Lig",
    "Mexico Liga MX",
    "Switzerland Super League",
    "Austria Bundesliga",
    "Norway Eliteserien",
    "Colombia Primera A",
    "South Korea K League 1",
    "Scotland Premiership",
    "Scotland Championship",
    "Saudi Pro League",
    "Greece Super League 1",
    "Morocco Botola Pro",
    "Romania Superliga",
    "Algeria Ligue 1",
    "Paraguay Primera Division",
    "Israel Ligat HaAl",
    "Uruguay Primera Division",
    "Costa Rica Primera Division",
    "Egypt Premier League",
    "Chile Primera Division",
    "Slovakia Super Liga",
    "Slovenia PrvaLiga",
    "Bolivia Primera Division",
    "UAE Pro League",
    "Azerbaijan Premier League",
    "South Africa Premier League",
    "Australia A-League",
    "Peru Primera Division",
    "Serbia SuperLiga",
    "Bulgaria First League",
    "Honduras Liga Nacional",
    "Bosnia Premier League",
    "Finland Veikkausliiga",
    "China CSL",
    "Qatar Stars League",
    "Venezuela Primera Division",
    "Canada Premier League",
    "USL Championship",
    "India Super League"
]

# Unify league filtering logic - use allow-list approach
def _is_target_league(league_obj: dict) -> bool:
    """Check if league is in the target list (allow-list approach)"""
    log.debug("üîç Starting league target check")
    if not league_obj:
        log.debug("‚ùå League object is empty")
        return False
    
    league_name = str(league_obj.get("name", "")).strip()
    country = str(league_obj.get("country", "")).strip()
    
    # Log what we're actually getting from the API
    log.debug("üîç Checking league: country='%s', name='%s'", country, league_name)
    
    # Try multiple formats
    possible_names = [
        f"{country} - {league_name}",
        f"{league_name}",
        f"{country} {league_name}",
        f"{league_name} - {country}"
    ]
    
    is_target = False
    for possible_name in possible_names:
        if possible_name in TARGET_LEAGUES:
            is_target = True
            log.debug("‚úÖ Matched as: %s", possible_name)
            break
    
    if is_target:
        log.debug("‚úÖ League accepted: %s - %s", country, league_name)
    else:
        log.debug("‚ùå League rejected: %s - %s", country, league_name)
        
    return is_target

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Optional import: trainer ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
try:
    log.info("ü§ñ Attempting to import train_models module")
    from train_models import train_models
    log.info("‚úÖ Successfully imported train_models")
except Exception as e:
    _IMPORT_ERR = repr(e)
    log.warning("‚ö†Ô∏è Failed to import train_models: %s", _IMPORT_ERR)
    def train_models(*args, **kwargs):  # type: ignore
        log.warning("üö´ train_models not available: %s", _IMPORT_ERR)
        return {"ok": False, "reason": f"train_models import failed: {_IMPORT_ERR}"}

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ DB pool & helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
POOL: Optional[SimpleConnectionPool] = None
class PooledConn:
    def __init__(self, pool): 
        log.debug("üîå Creating PooledConn instance")
        self.pool=pool; self.conn=None; self.cur=None
    
    def __enter__(self): 
        log.debug("üîå Acquiring connection from pool")
        self.conn=self.pool.getconn(); 
        self.conn.autocommit=True; 
        self.cur=self.conn.cursor(); 
        log.debug("‚úÖ Connection acquired and cursor created")
        return self
    
    def __exit__(self, a,b,c): 
        log.debug("üîå Releasing connection back to pool")
        try: 
            self.cur and self.cur.close()
            log.debug("‚úÖ Cursor closed")
        finally: 
            self.conn and self.pool.putconn(self.conn)
            log.debug("‚úÖ Connection returned to pool")
    
    def execute(self, sql: str, params: tuple|list=()):
        log.debug("üìù Executing SQL: %s with params: %s", sql[:100] + "..." if len(sql) > 100 else sql, params)
        self.cur.execute(sql, params or ())
        log.debug("‚úÖ SQL executed successfully")
        return self.cur

def _init_pool():
    global POOL
    log.info("üîå Initializing database connection pool")
    try:
        dsn = DATABASE_URL + (("&" if "?" in DATABASE_URL else "?") + "sslmode=require" if "sslmode=" not in DATABASE_URL else "")
        POOL = SimpleConnectionPool(minconn=1, maxconn=int(os.getenv("DB_POOL_MAX","5")), dsn=dsn)
        log.info("‚úÖ Database pool initialized: minconn=1, maxconn=%s", os.getenv("DB_POOL_MAX","5"))
        
        # Test the connection
        with PooledConn(POOL) as conn:
            conn.execute("SELECT 1")
            log.info("‚úÖ Database connection test successful")
    except Exception as e:
        log.critical("‚ùå Database connection failed: %s", e)
        raise SystemExit(f"Database connection failed: {e}")

def db_conn(): 
    if not POOL: 
        log.debug("üîå Pool not initialized, calling _init_pool")
        _init_pool()
    return PooledConn(POOL)  # type: ignore

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Settings cache ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
class _TTLCache:
    def __init__(self, ttl): 
        self.ttl=ttl; 
        self.data={}
        log.debug("üóÑÔ∏è Created TTL cache with TTL=%ds", ttl)
    
    def get(self, k): 
        log.debug("üóÑÔ∏è Cache GET for key: %s", k)
        v=self.data.get(k); 
        if not v: 
            log.debug("üóÑÔ∏è Cache MISS (key not found): %s", k)
            return None
        ts,val=v
        if time.time()-ts>self.ttl: 
            self.data.pop(k,None)
            log.debug("üóÑÔ∏è Cache EXPIRED for key: %s (age: %.2fs > TTL: %ds)", k, time.time()-ts, self.ttl)
            return None
        log.debug("üóÑÔ∏è Cache HIT for key: %s (age: %.2fs)", k, time.time()-ts)
        return val
    
    def set(self,k,v): 
        log.debug("üóÑÔ∏è Cache SET for key: %s", k)
        self.data[k]=(time.time(),v)
    
    def invalidate(self,k=None): 
        if k is None:
            log.debug("üóÑÔ∏è Cache CLEARED (all keys)")
            self.data.clear()
        else:
            log.debug("üóÑÔ∏è Cache INVALIDATE for key: %s", k)
            self.data.pop(k,None)

_SETTINGS_CACHE, _MODELS_CACHE = _TTLCache(SETTINGS_TTL), _TTLCache(MODELS_TTL)
log.info("üóÑÔ∏è Created caches: SETTINGS (TTL=%ds), MODELS (TTL=%ds)", SETTINGS_TTL, MODELS_TTL)

def get_setting(key: str) -> Optional[str]:
    log.debug("‚öôÔ∏è Getting setting from DB: %s", key)
    start_time = time.time()
    with db_conn() as c:
        r=c.execute("SELECT value FROM settings WHERE key=%s",(key,)).fetchone()
        elapsed = time.time() - start_time
        if r:
            log.debug("‚öôÔ∏è Setting retrieved: %s=%s (took %.3fs)", key, r[0], elapsed)
            return r[0]
        else:
            log.debug("‚öôÔ∏è Setting not found: %s (took %.3fs)", key, elapsed)
            return None

def set_setting(key: str, value: str) -> None:
    log.info("‚öôÔ∏è Setting value in DB: %s=%s", key, value)
    start_time = time.time()
    with db_conn() as c:
        c.execute("INSERT INTO settings(key,value) VALUES(%s,%s) ON CONFLICT(key) DO UPDATE SET value=EXCLUDED.value", (key,value))
        elapsed = time.time() - start_time
    log.debug("‚úÖ Setting saved: %s (took %.3fs)", key, elapsed)

def get_setting_cached(key: str) -> Optional[str]:
    log.debug("‚öôÔ∏è Getting cached setting: %s", key)
    v=_SETTINGS_CACHE.get(key)
    if v is None: 
        log.debug("‚öôÔ∏è Cache miss, fetching from DB: %s", key)
        v=get_setting(key); 
        _SETTINGS_CACHE.set(key,v)
    return v

def invalidate_model_caches_for_key(key: str):
    if key.lower().startswith(("model","model_latest","model_v2","pre_")):
        log.debug("üóÑÔ∏è Invalidating model cache for key: %s", key)
        _MODELS_CACHE.invalidate()
    else:
        log.debug("üóÑÔ∏è No model cache invalidation needed for key: %s", key)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Init DB ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def init_db():
    log.info("üóÑÔ∏è Initializing database schema")
    start_time = time.time()
    with db_conn() as c:
        log.debug("üìã Creating tables if they don't exist")
        c.execute("""CREATE TABLE IF NOT EXISTS tips (
            match_id BIGINT, league_id BIGINT, league TEXT,
            home TEXT, away TEXT, market TEXT, suggestion TEXT,
            confidence DOUBLE PRECISION, confidence_raw DOUBLE PRECISION,
            score_at_tip TEXT, minute INTEGER, created_ts BIGINT,
            odds DOUBLE PRECISION, book TEXT, ev_pct DOUBLE PRECISION,
            sent_ok INTEGER DEFAULT 1,
            PRIMARY KEY (match_id, created_ts))""")
        log.debug("‚úÖ Created/verified tips table")
        
        c.execute("""CREATE TABLE IF NOT EXISTS tip_snapshots (
            match_id BIGINT, created_ts BIGINT, payload TEXT,
            PRIMARY KEY (match_id, created_ts))""")
        log.debug("‚úÖ Created/verified tip_snapshots table")
        
        c.execute("""CREATE TABLE IF NOT EXISTS feedback (
            id SERIAL PRIMARY KEY, match_id BIGINT UNIQUE, verdict INTEGER, created_ts BIGINT)""")
        log.debug("‚úÖ Created/verified feedback table")
        
        c.execute("""CREATE TABLE IF NOT EXISTS settings (key TEXT PRIMARY KEY, value TEXT)""")
        log.debug("‚úÖ Created/verified settings table")
        
        c.execute("""CREATE TABLE IF NOT EXISTS match_results (
            match_id BIGINT PRIMARY KEY, final_goals_h INTEGER, final_goals_a INTEGER, btts_yes INTEGER, updated_ts BIGINT)""")
        log.debug("‚úÖ Created/verified match_results table")
        
        # Evolutive columns (idempotent)
        log.debug("üîß Checking for evolutive columns")
        try: 
            c.execute("ALTER TABLE tips ADD COLUMN IF NOT EXISTS odds DOUBLE PRECISION")
            log.debug("‚úÖ Added odds column if needed")
        except Exception as e: 
            log.debug("‚ÑπÔ∏è odds column already exists: %s", e)
        
        try: 
            c.execute("ALTER TABLE tips ADD COLUMN IF NOT EXISTS book TEXT")
            log.debug("‚úÖ Added book column if needed")
        except Exception as e: 
            log.debug("‚ÑπÔ∏è book column already exists: %s", e)
        
        try: 
            c.execute("ALTER TABLE tips ADD COLUMN IF NOT EXISTS ev_pct DOUBLE PRECISION")
            log.debug("‚úÖ Added ev_pct column if needed")
        except Exception as e: 
            log.debug("‚ÑπÔ∏è ev_pct column already exists: %s", e)
        
        try: 
            c.execute("ALTER TABLE tips ADD COLUMN IF NOT EXISTS confidence_raw DOUBLE PRECISION")
            log.debug("‚úÖ Added confidence_raw column if needed")
        except Exception as e: 
            log.debug("‚ÑπÔ∏è confidence_raw column already exists: %s", e)
        
        log.debug("üîß Creating indexes if they don't exist")
        c.execute("CREATE INDEX IF NOT EXISTS idx_tips_created ON tips (created_ts DESC)")
        log.debug("‚úÖ Created/verified idx_tips_created index")
        
        c.execute("CREATE INDEX IF NOT EXISTS idx_tips_match ON tips (match_id)")
        log.debug("‚úÖ Created/verified idx_tips_match index")
        
        c.execute("CREATE INDEX IF NOT EXISTS idx_tips_sent ON tips (sent_ok, created_ts DESC)")
        log.debug("‚úÖ Created/verified idx_tips_sent index")
        
        c.execute("CREATE INDEX IF NOT EXISTS idx_snap_by_match ON tip_snapshots (match_id, created_ts DESC)")
        log.debug("‚úÖ Created/verified idx_snap_by_match index")
        
        c.execute("CREATE INDEX IF NOT EXISTS idx_results_updated ON match_results (updated_ts DESC)")
        log.debug("‚úÖ Created/verified idx_results_updated index")
    
    elapsed = time.time() - start_time
    log.info("‚úÖ Database initialization completed in %.2f seconds", elapsed)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Telegram ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def send_telegram(text: str) -> bool:
    log.debug("üì± Preparing to send Telegram message")
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID: 
        log.warning("‚ö†Ô∏è Cannot send Telegram: missing BOT_TOKEN or CHAT_ID")
        return False
    try:
        log.debug("üì± Sending Telegram message (first 100 chars): %s", text[:100])
        start_time = time.time()
        r=session.post(f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage",
                       data={"chat_id":TELEGRAM_CHAT_ID,"text":text,"parse_mode":"HTML","disable_web_page_preview":True}, timeout=10)
        elapsed = time.time() - start_time
        if r.ok:
            log.info("‚úÖ Telegram sent successfully (took %.2fs)", elapsed)
            return True
        else:
            log.warning("‚ö†Ô∏è Telegram send failed: %s - %s", r.status_code, r.text)
            return False
    except Exception as e:
        log.error("‚ùå Telegram send error: %s", e)
        return False

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ API helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _api_get(url: str, params: dict, timeout: int = 15) -> Optional[dict]:
    log.debug("üåê API GET request: %s with params: %s", url, params)
    if not API_KEY: 
        log.warning("‚ö†Ô∏è No API_KEY available for request")
        return None
    try:
        start_time = time.time()
        r=session.get(url, headers=HEADERS, params=params, timeout=timeout)
        elapsed = time.time() - start_time
        if r.ok:
            log.debug("‚úÖ API request successful (took %.2fs, status: %s)", elapsed, r.status_code)
            return r.json()
        else:
            log.warning("‚ö†Ô∏è API request failed: %s - %s (took %.2fs)", r.status_code, r.text, elapsed)
            return None
    except Exception as e:
        elapsed = time.time() - start_time if 'start_time' in locals() else 0
        log.error("‚ùå API request error: %s (took %.2fs)", e, elapsed)
        return None

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ League filter ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
_BLOCK_PATTERNS = ["u17","u18","u19","u20","u21","u23","youth","junior","reserve","res.","friendlies","friendly"]
def _blocked_league(league_obj: dict) -> bool:
    """Check if league should be blocked (deny-list approach)"""
    log.debug("üö´ Checking if league is blocked")
    name=str((league_obj or {}).get("name","")).lower()
    country=str((league_obj or {}).get("country","")).lower()
    typ=str((league_obj or {}).get("type","")).lower()
    txt=f"{country} {name} {typ}"
    
    # Check for youth/reserve patterns
    for p in _BLOCK_PATTERNS:
        if p in txt:
            log.debug("üö´ League blocked by pattern '%s': %s", p, txt)
            return True
    
    # Check for specific league IDs from deny list
    deny=[x.strip() for x in os.getenv("LEAGUE_DENY_IDS","").split(",") if x.strip()]
    lid=str((league_obj or {}).get("id") or "")
    
    if lid in deny:
        log.debug("üö´ League blocked by ID in deny list: %s", lid)
        return True
    
    log.debug("‚úÖ League not blocked: %s", txt)
    return False

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Live fetches ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def fetch_match_stats(fid: int) -> list:
    log.debug("üìä Fetching match stats for fixture %s", fid)
    now=time.time()
    if fid in STATS_CACHE and now-STATS_CACHE[fid][0] < 90: 
        log.debug("üìä Using cached stats for fixture %s (age: %.1fs)", fid, now-STATS_CACHE[fid][0])
        return STATS_CACHE[fid][1]
    
    log.debug("üìä Cache miss, fetching fresh stats for fixture %s", fid)
    js=_api_get(f"{FOOTBALL_API_URL}/statistics", {"fixture": fid}) or {}
    out=js.get("response",[]) if isinstance(js,dict) else []
    STATS_CACHE[fid]=(now,out)
    log.debug("üìä Stats fetched for fixture %s: %s items", fid, len(out))
    return out

def fetch_match_events(fid: int) -> list:
    log.debug("‚öΩ Fetching match events for fixture %s", fid)
    now=time.time()
    if fid in EVENTS_CACHE and now-EVENTS_CACHE[fid][0] < 90: 
        log.debug("‚öΩ Using cached events for fixture %s (age: %.1fs)", fid, now-EVENTS_CACHE[fid][0])
        return EVENTS_CACHE[fid][1]
    
    log.debug("‚öΩ Cache miss, fetching fresh events for fixture %s", fid)
    js=_api_get(f"{FOOTBALL_API_URL}/events", {"fixture": fid}) or {}
    out=js.get("response",[]) if isinstance(js,dict) else []
    EVENTS_CACHE[fid]=(now,out)
    log.debug("‚öΩ Events fetched for fixture %s: %s items", fid, len(out))
    return out

def fetch_live_matches() -> List[dict]:
    log.info("üîç Fetching live matches")
    js=_api_get(FOOTBALL_API_URL, {"live":"all"}) or {}
    matches=[m for m in (js.get("response",[]) if isinstance(js,dict) else []) if _is_target_league(m.get("league") or {})]
    log.info("üìà Found %s live matches (after filtering)", len(matches))
    
    out=[]
    for m in matches:
        st=((m.get("fixture",{}) or {}).get("status",{}) or {})
        elapsed=st.get("elapsed"); short=(st.get("short") or "").upper()
        if elapsed is None or elapsed>120 or short not in INPLAY_STATUSES: 
            log.debug("‚è≠Ô∏è Skipping match: elapsed=%s, short=%s", elapsed, short)
            continue
        
        fid=(m.get("fixture",{}) or {}).get("id")
        log.debug("üîÑ Fetching stats and events for fixture %s", fid)
        m["statistics"]=fetch_match_stats(fid); 
        m["events"]=fetch_match_events(fid)
        out.append(m)
    
    log.info("‚úÖ Live matches processed: %s matches ready for analysis", len(out))
    return out

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Prematch helpers (short) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _api_last_fixtures(team_id: int, n: int = 5) -> List[dict]:
    log.debug("üìÖ Fetching last %s fixtures for team %s", n, team_id)
    js=_api_get(f"{BASE_URL}/fixtures", {"team":team_id,"last":n}) or {}
    result = js.get("response",[]) if isinstance(js,dict) else []
    log.debug("üìÖ Found %s past fixtures for team %s", len(result), team_id)
    return result

def _api_h2h(home_id: int, away_id: int, n: int = 5) -> List[dict]:
    log.debug("ü§ù Fetching H2H for %s vs %s (last %s)", home_id, away_id, n)
    js=_api_get(f"{BASE_URL}/fixtures/headtohead", {"h2h":f"{home_id}-{away_id}","last":n}) or {}
    result = js.get("response",[]) if isinstance(js,dict) else []
    log.debug("ü§ù Found %s H2H fixtures for %s vs %s", len(result), home_id, away_id)
    return result

def _collect_todays_prematch_fixtures() -> List[dict]:
    log.info("üìÖ Collecting today's prematch fixtures")
    today_local=datetime.now(BERLIN_TZ).date()
    start_local=datetime.combine(today_local, datetime.min.time(), tzinfo=BERLIN_TZ)
    end_local=start_local+timedelta(days=1)
    dates_utc={start_local.astimezone(TZ_UTC).date(), (end_local - timedelta(seconds=1)).astimezone(TZ_UTC).date()}
    
    log.debug("üìÖ Date range: %s (Berlin) -> UTC dates: %s", today_local, dates_utc)
    
    fixtures=[]
    for d in sorted(dates_utc):
        log.debug("üìÖ Fetching fixtures for date: %s", d)
        js=_api_get(FOOTBALL_API_URL, {"date": d.strftime("%Y-%m-%d")}) or {}
        for r in js.get("response",[]) if isinstance(js,dict) else []:
            if (((r.get("fixture") or {}).get("status") or {}).get("short") or "").upper() == "NS":
                fixtures.append(r)
    
    log.debug("üìÖ Found %s total fixtures, filtering blocked leagues", len(fixtures))
    fixtures=[f for f in fixtures if _is_target_league(f.get("league") or {})]
    log.info("‚úÖ Today's prematch fixtures: %s matches", len(fixtures))
    return fixtures

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Feature extraction (live) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _num(v) -> float:
    try:
        if isinstance(v,str) and v.endswith("%"): 
            result = float(v[:-1])
            log.debug("üî¢ Converted percentage string '%s' to float: %s", v, result)
            return result
        result = float(v or 0)
        log.debug("üî¢ Converted '%s' to float: %s", v, result)
        return result
    except Exception as e:
        log.debug("üî¢ Failed to convert '%s' to float, using 0.0: %s", v, e)
        return 0.0

def _pos_pct(v) -> float:
    try: 
        result = float(str(v).replace("%","").strip() or 0)
        log.debug("üéØ Converted position percentage '%s' to float: %s", v, result)
        return result
    except Exception as e:
        log.debug("üéØ Failed to convert position percentage '%s', using 0.0: %s", v, e)
        return 0.0

def extract_features(m: dict) -> Dict[str,float]:
    log.debug("üìä Extracting features from match data")
    home=m["teams"]["home"]["name"]; away=m["teams"]["away"]["name"]
    gh=m["goals"]["home"] or 0; ga=m["goals"]["away"] or 0
    minute=int(((m.get("fixture") or {}).get("status") or {}).get("elapsed") or 0)
    
    log.debug("üìä Match: %s vs %s, Score: %s-%s, Minute: %s", home, away, gh, ga, minute)
    
    stats={}
    for s in (m.get("statistics") or []):
        t=(s.get("team") or {}).get("name")
        if t: 
            stats[t]={ (i.get("type") or ""): i.get("value") for i in (s.get("statistics") or []) }
            log.debug("üìä Stats for team %s: %s items", t, len(stats[t]))
    
    sh=stats.get(home,{}) or {}; sa=stats.get(away,{}) or {}
    
    # Extract individual stats
    xg_h=_num(sh.get("Expected Goals",0)); xg_a=_num(sa.get("Expected Goals",0))
    sot_h=_num(sh.get("Shots on Target",0)); sot_a=_num(sa.get("Shots on Target",0))
    cor_h=_num(sh.get("Corner Kicks",0)); cor_a=_num(sa.get("Corner Kicks",0))
    pos_h=_pos_pct(sh.get("Ball Possession",0)); pos_a=_pos_pct(sa.get("Ball Possession",0))
    
    log.debug("üìä Basic stats - xG: %s-%s, SOT: %s-%s, Corners: %s-%s, Possession: %s%%-%s%%", 
              xg_h, xg_a, sot_h, sot_a, cor_h, cor_a, pos_h, pos_a)
    
    # Count red cards
    red_h=red_a=0
    for ev in (m.get("events") or []):
        if (ev.get("type","").lower()=="card"):
            d=(ev.get("detail","") or "").lower()
            if "red" in d or "second yellow" in d:
                t=(ev.get("team") or {}).get("name") or ""
                if t==home: red_h+=1
                elif t==away: red_a+=1
    
    log.debug("üìä Red cards: %s-%s", red_h, red_a)
    
    features = {
        "minute":float(minute),
        "goals_h":float(gh),"goals_a":float(ga),"goals_sum":float(gh+ga),"goals_diff":float(gh-ga),
        "xg_h":float(xg_h),"xg_a":float(xg_a),"xg_sum":float(xg_h+xg_a),"xg_diff":float(xg_h-xg_a),
        "sot_h":float(sot_h),"sot_a":float(sot_a),"sot_sum":float(sot_h+sot_a),
        "cor_h":float(cor_h),"cor_a":float(cor_a),"cor_sum":float(cor_h+cor_a),
        "pos_h":float(pos_h),"pos_a":float(pos_a),"pos_diff":float(pos_h-pos_a),
        "red_h":float(red_h),"red_a":float(red_a),"red_sum":float(red_h+red_a)
    }
    
    log.debug("‚úÖ Features extracted: %s", {k: round(v, 2) for k, v in features.items()})
    return features

def stats_coverage_ok(feat: Dict[str,float], minute: int) -> bool:
    log.debug("üìä Checking stats coverage for minute %s", minute)
    require_stats_minute=int(os.getenv("REQUIRE_STATS_MINUTE","35"))
    require_fields=int(os.getenv("REQUIRE_DATA_FIELDS","2"))
    
    if minute < require_stats_minute: 
        log.debug("‚úÖ Stats coverage OK (minute %s < required %s)", minute, require_stats_minute)
        return True
    
    fields=[feat.get("xg_sum",0.0), feat.get("sot_sum",0.0), feat.get("cor_sum",0.0),
            max(feat.get("pos_h",0.0), feat.get("pos_a",0.0))]
    
    nonzero=sum(1 for v in fields if (v or 0)>0)
    result = nonzero >= max(0, require_fields)
    
    log.debug("üìä Stats coverage check: %s non-zero fields (need %s) -> %s", 
              nonzero, require_fields, "OK" if result else "FAIL")
    return result

def _league_name(m: dict) -> Tuple[int,str]:
    lg=(m.get("league") or {}) or {}
    league_id = int(lg.get("id") or 0)
    league_name = f"{lg.get('country','')} - {lg.get('name','')}".strip(" -")
    log.debug("üèÜ League: ID=%s, Name=%s", league_id, league_name)
    return league_id, league_name

def _teams(m: dict) -> Tuple[str,str]:
    t=(m.get("teams") or {}) or {}
    home = t.get("home",{}).get("name","")
    away = t.get("away",{}).get("name","")
    log.debug("üë• Teams: %s vs %s", home, away)
    return home, away

def _pretty_score(m: dict) -> str:
    gh=(m.get("goals") or {}).get("home") or 0; ga=(m.get("goals") or {}).get("away") or 0
    score = f"{gh}-{ga}"
    log.debug("üìä Score: %s", score)
    return score

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Models ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
MODEL_KEYS_ORDER=["model_v2:{name}","model_latest:{name}","model:{name}"]
EPS=1e-12

def _sigmoid(x: float) -> float:
    try:
        if x<-50: 
            result = 1e-22
            log.debug("üìà Sigmoid(%s) -> %s (clamped low)", x, result)
            return result
        if x>50:  
            result = 1-1e-22
            log.debug("üìà Sigmoid(%s) -> %s (clamped high)", x, result)
            return result
        import math; 
        result = 1/(1+math.exp(-x))
        log.debug("üìà Sigmoid(%s) -> %s", x, result)
        return result
    except Exception as e:
        log.error("‚ùå Sigmoid calculation error: %s, using 0.5", e)
        return 0.5

def _logit(p: float) -> float:
    import math; 
    p=max(EPS,min(1-EPS,float(p))); 
    result = math.log(p/(1-p))
    log.debug("üìà Logit(%s) -> %s", p, result)
    return result

def load_model_from_settings(name: str) -> Optional[Dict[str,Any]]:
    log.debug("ü§ñ Loading model: %s", name)
    cached=_MODELS_CACHE.get(name)
    if cached is not None: 
        log.debug("ü§ñ Model cache HIT: %s", name)
        return cached
    
    log.debug("ü§ñ Model cache MISS: %s", name)
    mdl=None
    for pat in MODEL_KEYS_ORDER:
        key = pat.format(name=name)
        log.debug("ü§ñ Trying model key: %s", key)
        raw=get_setting_cached(key)
        if not raw: 
            log.debug("ü§ñ Model key not found: %s", key)
            continue
        
        try:
            tmp=json.loads(raw); 
            tmp.setdefault("intercept",0.0); 
            tmp.setdefault("weights",{})
            cal=tmp.get("calibration") or {}; 
            if isinstance(cal,dict): 
                cal.setdefault("method","sigmoid"); 
                cal.setdefault("a",1.0); 
                cal.setdefault("b",0.0); 
                tmp["calibration"]=cal
            mdl=tmp; 
            log.info("‚úÖ Model loaded successfully: %s", name)
            log.debug("ü§ñ Model details - intercept: %s, weights: %s keys, calibration: %s", 
                     tmp.get("intercept"), len(tmp.get("weights", {})), tmp.get("calibration"))
            break
        except Exception as e:
            log.warning("‚ö†Ô∏è Model parse failed for %s: %s", name, e)
    
    if mdl is not None: 
        _MODELS_CACHE.set(name, mdl)
    else:
        log.warning("‚ö†Ô∏è Model not found: %s", name)
    return mdl

def _linpred(feat: Dict[str,float], weights: Dict[str,float], intercept: float) -> float:
    log.debug("üßÆ Calculating linear prediction")
    s=float(intercept or 0.0)
    for k,w in (weights or {}).items(): 
        feat_val = float(feat.get(k,0.0))
        s += float(w or 0.0) * feat_val
        log.debug("üßÆ Weight * feature: %s * %s = %s (cumulative: %s)", w, feat_val, w*feat_val, s)
    log.debug("üßÆ Linear prediction result: %s", s)
    return s

def _calibrate(p: float, cal: Dict[str,Any]) -> float:
    method=(cal or {}).get("method","sigmoid"); 
    a=float((cal or {}).get("a",1.0)); 
    b=float((cal or {}).get("b",0.0))
    
    log.debug("üéØ Calibrating probability %s with method %s, a=%s, b=%s", p, method, a, b)
    
    if method.lower()=="platt": 
        result = _sigmoid(a*_logit(p)+b)
        log.debug("üéØ Platt calibration result: %s", result)
        return result
    
    import math; 
    p=max(EPS,min(1-EPS,float(p))); 
    z=math.log(p/(1-p)); 
    result = _sigmoid(a*z+b)
    log.debug("üéØ Sigmoid calibration result: %s", result)
    return result

def _score_prob(feat: Dict[str,float], mdl: Dict[str,Any]) -> float:
    log.debug("üìà Scoring probability with model")
    p=_sigmoid(_linpred(feat, mdl.get("weights",{}), float(mdl.get("intercept",0.0))))
    log.debug("üìà Raw probability before calibration: %s", p)
    
    cal=mdl.get("calibration") or {}
    try: 
        if cal: 
            p=_calibrate(p, cal)
            log.debug("üìà Probability after calibration: %s", p)
    except Exception as e:
        log.warning("‚ö†Ô∏è Calibration failed: %s", e)
        pass
    
    result = max(0.0, min(1.0, float(p)))
    log.debug("üìà Final probability: %s", result)
    return result

def _load_ou_model_for_line(line: float) -> Optional[Dict[str,Any]]:
    name=f"OU_{_fmt_line(line)}"
    log.debug("üéØ Loading OU model for line %s (name: %s)", line, name)
    mdl=load_model_from_settings(name)
    
    if not mdl and abs(line-2.5)<1e-6:
        log.debug("üéØ Falling back to O25 model for line 2.5")
        mdl = load_model_from_settings("O25")
    
    if mdl:
        log.debug("‚úÖ OU model loaded for line %s", line)
    else:
        log.debug("‚ö†Ô∏è No OU model found for line %s", line)
    return mdl

def _load_wld_models() -> Tuple[Optional[Dict[str,Any]], Optional[Dict[str,Any]], Optional[Dict[str,Any]]]:
    log.debug("üèÜ Loading Win/Lose/Draw models")
    home_model = load_model_from_settings("WLD_HOME")
    draw_model = load_model_from_settings("WLD_DRAW")
    away_model = load_model_from_settings("WLD_AWAY")
    
    log.debug("üèÜ WLD models loaded - Home: %s, Draw: %s, Away: %s", 
             "‚úì" if home_model else "‚úó", 
             "‚úì" if draw_model else "‚úó", 
             "‚úì" if away_model else "‚úó")
    
    return home_model, draw_model, away_model

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Odds helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _ev(prob: float, odds: float) -> float:
    """Return expected value as decimal (e.g. 0.05 = +5%)."""
    result = prob*max(0.0, float(odds)) - 1.0
    log.debug("üí∞ EV calculation: prob=%s * odds=%s - 1 = %s", prob, odds, result)
    return result

def _min_odds_for_market(market: str) -> float:
    if market.startswith("Over/Under"): 
        result = MIN_ODDS_OU
    elif market == "BTTS": 
        result = MIN_ODDS_BTTS
    elif market == "1X2":  
        result = MIN_ODDS_1X2
    else:
        result = 1.01
    
    log.debug("üí∞ Min odds for market '%s': %s", market, result)
    return result

def _odds_cache_get(fid: int) -> Optional[dict]:
    rec=ODDS_CACHE.get(fid)
    if not rec: 
        log.debug("üí∞ Odds cache MISS for fixture %s", fid)
        return None
    
    ts,data=rec
    if time.time()-ts>120: 
        ODDS_CACHE.pop(fid,None)
        log.debug("üí∞ Odds cache EXPIRED for fixture %s (age: %.1fs)", fid, time.time()-ts)
        return None
    
    log.debug("üí∞ Odds cache HIT for fixture %s (age: %.1fs)", fid, time.time()-ts)
    return data

def _market_name_normalize(s: str) -> str:
    s=(s or "").lower()
    if "both teams" in s or "btts" in s: 
        result = "BTTS"
    elif "match winner" in s or "winner" in s or "1x2" in s: 
        result = "1X2"
    elif "over/under" in s or "total" in s or "goals" in s: 
        result = "OU"
    else:
        result = s
    
    log.debug("üè∑Ô∏è Market name normalized: '%s' -> '%s'", s, result)
    return result

def fetch_odds(fid: int) -> dict:
    """
    Returns a dict like:
    {
      "BTTS": {"Yes": {"odds":1.90,"book":"X"}, "No": {...}},
      "1X2":  {"Home": {...}, "Away": {...}},
      "OU_2.5": {"Over": {...}, "Under": {...}},
      "OU_3.5": {...}
    }
    Best-effort parsing of API-Football /odds endpoint; tolerate missing data.
    """
    log.debug("üí∞ Fetching odds for fixture %s", fid)
    cached=_odds_cache_get(fid)
    if cached is not None: 
        log.debug("üí∞ Returning cached odds for fixture %s", fid)
        return cached
    
    params={"fixture": fid}
    if ODDS_BOOKMAKER_ID: 
        params["bookmaker"] = ODDS_BOOKMAKER_ID
        log.debug("üí∞ Using specific bookmaker: %s", ODDS_BOOKMAKER_ID)
    
    js=_api_get(f"{BASE_URL}/odds", params) or {}
    out={}
    try:
        log.debug("üí∞ Processing odds response for fixture %s", fid)
        for r in js.get("response",[]) if isinstance(js,dict) else []:
            book=(r.get("bookmakers") or [])
            if not book: 
                log.debug("üí∞ No bookmakers in response")
                continue
            
            bk=book[0]; book_name=bk.get("name") or "Book"
            log.debug("üí∞ Processing bookmaker: %s", book_name)
            
            for mkt in (bk.get("bets") or []):
                mname=_market_name_normalize(mkt.get("name",""))
                vals=mkt.get("values") or []
                log.debug("üí∞ Processing market: %s with %s values", mname, len(vals))
                
                # BTTS
                if mname=="BTTS":
                    d={}
                    for v in vals:
                        lbl=(v.get("value") or "").strip().lower()
                        if "yes" in lbl: d["Yes"]={"odds":float(v.get("odd") or 0), "book":book_name}
                        if "no"  in lbl: d["No"] ={"odds":float(v.get("odd") or 0), "book":book_name}
                    if d: 
                        out["BTTS"]=d
                        log.debug("üí∞ BTTS odds found: %s", d)
                
                # 1X2
                elif mname=="1X2":
                    d={}
                    for v in vals:
                        lbl=(v.get("value") or "").strip().lower()
                        if lbl in ("home","1"): d["Home"]={"odds":float(v.get("odd") or 0),"book":book_name}
                        if lbl in ("away","2"): d["Away"]={"odds":float(v.get("odd") or 0),"book":book_name}
                    if d: 
                        out["1X2"]=d
                        log.debug("üí∞ 1X2 odds found: %s", d)
                
                # OU lines
                elif mname=="OU":
                    # values like "Over 2.5", "Under 2.5"
                    by_line={}
                    for v in vals:
                        lbl=(v.get("value") or "").lower()
                        if "over" in lbl or "under" in lbl:
                            try:
                                ln=float(lbl.split()[-1])
                                key=f"OU_{_fmt_line(ln)}"
                                side="Over" if "over" in lbl else "Under"
                                by_line.setdefault(key,{}).update({side: {"odds":float(v.get("odd") or 0),"book":book_name}})
                                log.debug("üí∞ OU odds: %s %s @ %s", side, ln, v.get("odd"))
                            except Exception as e:
                                log.debug("üí∞ Failed to parse OU label '%s': %s", lbl, e)
                    for k,v in by_line.items(): 
                        out[k]=v
                        log.debug("üí∞ Added OU market %s: %s", k, v)
        
        ODDS_CACHE[fid]=(time.time(), out)
        log.info("‚úÖ Odds fetched for fixture %s: %s markets", fid, len(out))
    except Exception as e:
        log.error("‚ùå Error fetching odds for fixture %s: %s", fid, e)
        out={}
    
    return out

def _price_gate(market_text: str, suggestion: str, fid: int) -> Tuple[bool, Optional[float], Optional[str], Optional[float]]:
    """
    Return (pass, odds, book, ev_pct). If odds missing:
      - pass if ALLOW_TIPS_WITHOUT_ODDS else block.
    """
    log.debug("üí∞ Price gate check for market '%s', suggestion '%s', fixture %s", 
              market_text, suggestion, fid)
    
    odds_map=fetch_odds(fid) if API_KEY else {}
    log.debug("üí∞ Odds map for fixture %s: %s", fid, list(odds_map.keys()))
    
    odds=None; book=None
    if market_text=="BTTS":
        d=odds_map.get("BTTS",{})
        tgt="Yes" if suggestion.endswith("Yes") else "No"
        if tgt in d: 
            odds=d[tgt]["odds"]; book=d[tgt]["book"]
            log.debug("üí∞ BTTS odds found: %s @ %s (book: %s)", tgt, odds, book)
    elif market_text=="1X2":
        d=odds_map.get("1X2",{})
        tgt="Home" if suggestion=="Home Win" else ("Away" if suggestion=="Away Win" else None)
        if tgt and tgt in d: 
            odds=d[tgt]["odds"]; book=d[tgt]["book"]
            log.debug("üí∞ 1X2 odds found: %s @ %s (book: %s)", tgt, odds, book)
    elif market_text.startswith("Over/Under"):
        ln=_fmt_line(float(suggestion.split()[1]))
        d=odds_map.get(f"OU_{ln}",{})
        tgt="Over" if suggestion.startswith("Over") else "Under"
        if tgt in d: 
            odds=d[tgt]["odds"]; book=d[tgt]["book"]
            log.debug("üí∞ OU odds found: %s %s @ %s (book: %s)", tgt, ln, odds, book)

    if odds is None:
        log.debug("üí∞ No odds found for suggestion")
        if ALLOW_TIPS_WITHOUT_ODDS:
            log.debug("üí∞ Allowing tip without odds (ALLOW_TIPS_WITHOUT_ODDS=True)")
            return (ALLOW_TIPS_WITHOUT_ODDS, None, None, None)
        else:
            log.debug("üí∞ Blocking tip without odds (ALLOW_TIPS_WITHOUT_ODDS=False)")
            return (False, odds, book, None)

    # price range gates
    min_odds=_min_odds_for_market(market_text)
    if not (min_odds <= odds <= MAX_ODDS_ALL):
        log.debug("üí∞ Odds %s outside range [%s, %s] -> BLOCKED", odds, min_odds, MAX_ODDS_ALL)
        return (False, odds, book, None)

    # EV calculation flow (completed)
    log.debug("üí∞ Calculating expected value (EV)")
    ev_pct = None
    if odds is not None and market_text:
        # We need probability for EV calculation
        # This should be called from production_scan or prematch_scan where probability is available
        log.debug("üí∞ EV calculation will be completed in production_scan with probability")
    
    log.debug("üí∞ Price gate PASSED: odds=%s, book=%s", odds, book)
    return (True, odds, book, ev_pct)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Snapshots ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def save_snapshot_from_match(m: dict, feat: Dict[str,float]) -> None:
    log.debug("üì∏ Saving snapshot from match")
    fx=m.get("fixture",{}) or {}; lg=m.get("league",{}) or {}
    fid=int(fx.get("id")); league_id=int(lg.get("id") or 0)
    league=f"{lg.get('country','')} - {lg.get('name','')}".strip(" -")
    home=(m.get("teams") or {}).get("home",{}).get("name","")
    away=(m.get("teams") or {}).get("away",{}).get("name","")
    gh=(m.get("goals") or {}).get("home") or 0; ga=(m.get("goals") or {}).get("away") or 0
    minute=int(feat.get("minute",0))
    
    snapshot={
        "minute":minute,
        "gh":gh,"ga":ga,
        "league_id":league_id,
        "market":"HARVEST",
        "suggestion":"HARVEST",
        "confidence":0,
        "stat":{
            "xg_h":feat.get("xg_h",0),
            "xg_a":feat.get("xg_a",0),
            "sot_h":feat.get("sot_h",0),
            "sot_a":feat.get("sot_a",0),
            "cor_h":feat.get("cor_h",0),
            "cor_a":feat.get("cor_a",0),
            "pos_h":feat.get("pos_h",0),
            "pos_a":feat.get("pos_a",0),
            "red_h":feat.get("red_h",0),
            "red_a":feat.get("red_a",0)
        }
    }
    
    now=int(time.time())
    log.debug("üì∏ Creating snapshot for fixture %s at minute %s", fid, minute)
    
    with db_conn() as c:
        c.execute("INSERT INTO tip_snapshots(match_id, created_ts, payload) VALUES (%s,%s,%s) "
                  "ON CONFLICT (match_id, created_ts) DO UPDATE SET payload=EXCLUDED.payload",
                  (fid, now, json.dumps(snapshot)[:200000]))
        log.debug("‚úÖ Snapshot saved to tip_snapshots")
        
        c.execute("INSERT INTO tips(match_id,league_id,league,home,away,market,suggestion,confidence,confidence_raw,score_at_tip,minute,created_ts,sent_ok) "
                  "VALUES (%s,%s,%s,%s,%s,'HARVEST','HARVEST',0.0,0.0,%s,%s,%s,1)",
                  (fid, league_id, league, home, away, f"{gh}-{ga}", minute, now))
        log.debug("‚úÖ Harvest record saved to tips")
    
    log.info("üì∏ Snapshot saved for %s vs %s (minute %s)", home, away, minute)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Format tip message function (moved up) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _format_tip_message(home, away, league, minute, score, suggestion, prob_pct, feat, odds=None, book=None, ev_pct=None):
    log.debug("‚úçÔ∏è Formatting tip message")
    stat=""
    if any([feat.get("xg_h",0),feat.get("xg_a",0),feat.get("sot_h",0),feat.get("sot_a",0),feat.get("cor_h",0),feat.get("cor_a",0),
            feat.get("pos_h",0),feat.get("pos_a",0),feat.get("red_h",0),feat.get("red_a",0)]):
        stat=(f"\nüìä xG {feat.get('xg_h',0):.2f}-{feat.get('xg_a',0):.2f}"
              f" ‚Ä¢ SOT {int(feat.get('sot_h',0))}-{int(feat.get('sot_a',0))}"
              f" ‚Ä¢ CK {int(feat.get('cor_h',0))}-{int(feat.get('cor_a',0))}")
        if feat.get("pos_h",0) or feat.get("pos_a",0): 
            stat += f" ‚Ä¢ POS {int(feat.get('pos_h',0))}%‚Äì{int(feat.get('pos_a',0))}%"
        if feat.get("red_h",0) or feat.get("red_a",0): 
            stat += f" ‚Ä¢ RED {int(feat.get('red_h',0))}-{int(feat.get('red_a',0))}"
    
    money = ""
    if odds:
        if ev_pct is not None:
            money = f"\nüí∞ <b>Odds:</b> {odds:.2f} @ {book or 'Book'}  ‚Ä¢  <b>EV:</b> {ev_pct:+.1f}%"
        else:
            money = f"\nüí∞ <b>Odds:</b> {odds:.2f} @ {book or 'Book'}"
    
    message = ("‚öΩÔ∏è <b>New Tip!</b>\n"
            f"<b>Match:</b> {escape(home)} vs {escape(away)}\n"
            f"üïí <b>Minute:</b> {minute}'  |  <b>Score:</b> {escape(score)}\n"
            f"<b>Tip:</b> {escape(suggestion)}\n"
            f"üìà <b>Confidence:</b> {prob_pct:.1f}%{money}\n"
            f"üèÜ <b>League:</b> {escape(league)}{stat}")
    
    log.debug("‚úÖ Tip message formatted (length: %s chars)", len(message))
    return message

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Send tip function (moved before it's called) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _send_tip(home,away,league,minute,score,suggestion,prob_pct,feat,odds=None,book=None,ev_pct=None)->bool:
    log.debug("üì± Sending tip via Telegram")
    message = _format_tip_message(home,away,league,minute,score,suggestion,prob_pct,feat,odds,book,ev_pct)
    result = send_telegram(message)
    log.debug("üì± Tip send result: %s", "SUCCESS" if result else "FAILED")
    return result

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Outcomes/backfill/digest (short) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _parse_ou_line_from_suggestion(s: str) -> Optional[float]:
    try:
        log.debug("üìê Parsing OU line from suggestion: %s", s)
        for tok in (s or "").split():
            try: 
                result = float(tok)
                log.debug("üìê Found line: %s", result)
                return result
            except: 
                continue
    except Exception as e:
        log.debug("üìê Failed to parse OU line: %s", e)
        pass
    return None

def _tip_outcome_for_result(suggestion: str, res: Dict[str,Any]) -> Optional[int]:
    log.debug("üìä Calculating tip outcome for suggestion: %s", suggestion)
    gh=int(res.get("final_goals_h") or 0); ga=int(res.get("final_goals_a") or 0)
    total=gh+ga; btts=int(res.get("btts_yes") or 0); s=(suggestion or "").strip()
    
    log.debug("üìä Final score: %s-%s (total: %s, BTTS: %s)", gh, ga, total, btts)
    
    if s.startswith("Over") or s.startswith("Under"):
        line=_parse_ou_line_from_suggestion(s); 
        if line is None: 
            log.debug("üìä Could not parse line from suggestion")
            return None
        
        if s.startswith("Over"):
            if total>line: 
                log.debug("üìä OVER WIN: total %s > line %s", total, line)
                return 1
            if abs(total-line)<1e-9: 
                log.debug("üìä OVER PUSH: total %s == line %s", total, line)
                return None
            log.debug("üìä OVER LOSS: total %s <= line %s", total, line)
            return 0
        else:
            if total<line: 
                log.debug("üìä UNDER WIN: total %s < line %s", total, line)
                return 1
            if abs(total-line)<1e-9: 
                log.debug("üìä UNDER PUSH: total %s == line %s", total, line)
                return None
            log.debug("üìä UNDER LOSS: total %s >= line %s", total, line)
            return 0
    
    if s=="BTTS: Yes": 
        result = 1 if btts==1 else 0
        log.debug("üìä BTTS: Yes -> %s (actual BTTS: %s)", "WIN" if result==1 else "LOSS", btts)
        return result
    
    if s=="BTTS: No":  
        result = 1 if btts==0 else 0
        log.debug("üìä BTTS: No -> %s (actual BTTS: %s)", "WIN" if result==1 else "LOSS", btts)
        return result
    
    if s=="Home Win":  
        result = 1 if gh>ga else 0
        log.debug("üìä Home Win -> %s (score: %s-%s)", "WIN" if result==1 else "LOSS", gh, ga)
        return result
    
    if s=="Away Win":  
        result = 1 if ga>gh else 0
        log.debug("üìä Away Win -> %s (score: %s-%s)", "WIN" if result==1 else "LOSS", gh, ga)
        return result
    
    log.debug("üìä Unknown suggestion type: %s", s)
    return None

def _fixture_by_id(mid: int) -> Optional[dict]:
    log.debug("üîç Fetching fixture by ID: %s", mid)
    js=_api_get(FOOTBALL_API_URL, {"id": mid}) or {}
    arr=js.get("response") or [] if isinstance(js,dict) else []
    result = arr[0] if arr else None
    if result:
        log.debug("‚úÖ Found fixture %s", mid)
    else:
        log.debug("‚ö†Ô∏è Fixture not found: %s", mid)
    return result

def _is_final(short: str) -> bool: 
    result = (short or "").upper() in {"FT","AET","PEN"}
    log.debug("üìä Is final status '%s'? %s", short, result)
    return result

def backfill_results_for_open_matches(max_rows: int = 200) -> int:
    log.info("üîÑ Starting backfill for open matches (max %s rows)", max_rows)
    now_ts=int(time.time()); cutoff=now_ts - BACKFILL_DAYS*24*3600; updated=0
    
    log.debug("üîÑ Looking for matches without results (cutoff: %s days ago)", BACKFILL_DAYS)
    with db_conn() as c:
        rows=c.execute("""
            WITH last AS (SELECT match_id, MAX(created_ts) last_ts FROM tips WHERE created_ts >= %s GROUP BY match_id)
            SELECT l.match_id FROM last l LEFT JOIN match_results r ON r.match_id=l.match_id
            WHERE r.match_id IS NULL ORDER BY l.last_ts DESC LIMIT %s
        """,(cutoff, max_rows)).fetchall()
    
    log.debug("üîÑ Found %s matches without results", len(rows))
    
    for (mid,) in rows:
        log.debug("üîÑ Processing match %s", mid)
        fx=_fixture_by_id(int(mid))
        if not fx: 
            log.debug("üîÑ Fixture not found: %s", mid)
            continue
        
        st=(((fx.get("fixture") or {}).get("status") or {}).get("short") or "")
        if not _is_final(st): 
            log.debug("üîÑ Match not final: %s (status: %s)", mid, st)
            continue
        
        g=fx.get("goals") or {}; gh=int(g.get("home") or 0); ga=int(g.get("away") or 0)
        btts=1 if (gh>0 and ga>0) else 0
        
        log.debug("üîÑ Final score for %s: %s-%s (BTTS: %s)", mid, gh, ga, btts)
        
        with db_conn() as c2:
            c2.execute("INSERT INTO match_results(match_id, final_goals_h, final_goals_a, btts_yes, updated_ts) "
                       "VALUES(%s,%s,%s,%s,%s) ON CONFLICT(match_id) DO UPDATE SET final_goals_h=EXCLUDED.final_goals_h, "
                       "final_goals_a=EXCLUDED.final_goals_a, btts_yes=EXCLUDED.btts_yes, updated_ts=EXCLUDED.updated_ts",
                       (int(mid), gh, ga, btts, int(time.time())))
        
        updated+=1
        log.debug("üîÑ Updated result for match %s", mid)
    
    if updated: 
        log.info("‚úÖ Backfill completed: %s matches updated", updated)
    else:
        log.info("‚ÑπÔ∏è Backfill: no matches needed updating")
    return updated

def daily_accuracy_digest() -> Optional[str]:
    if not DAILY_ACCURACY_DIGEST_ENABLE: 
        log.info("üìä Daily digest disabled")
        return None
    
    log.info("üìä Generating daily accuracy digest")
    now_local=datetime.now(BERLIN_TZ)
    y0=(now_local - timedelta(days=1)).replace(hour=0,minute=0,second=0,microsecond=0); y1=y0+timedelta(days=1)
    
    log.debug("üìä Date range: %s to %s (Berlin time)", y0, y1)
    
    # Ensure we have latest results
    backfill_results_for_open_matches(400)
    
    with db_conn() as c:
        rows=c.execute("""
            SELECT t.match_id, t.market, t.suggestion, t.confidence, t.confidence_raw, t.created_ts,
                   r.final_goals_h, r.final_goals_a, r.btts_yes
            FROM tips t LEFT JOIN match_results r ON r.match_id=t.match_id
            WHERE t.created_ts >= %s AND t.created_ts < %s AND t.suggestion<>'HARVEST' AND t.sent_ok=1
        """,(int(y0.timestamp()), int(y1.timestamp()))).fetchall()
    
    log.debug("üìä Found %s tips from yesterday", len(rows))
    
    total=graded=wins=0; by={}
    for (mid, mkt, sugg, conf, conf_raw, cts, gh, ga, btts) in rows:
        res={"final_goals_h":gh,"final_goals_a":ga,"btts_yes":btts}
        out=_tip_outcome_for_result(sugg,res)
        if out is None: 
            log.debug("üìä Tip %s (match %s) not gradable", sugg, mid)
            continue
        
        total+=1; graded+=1; wins+=1 if out==1 else 0
        d=by.setdefault(mkt or "?",{"graded":0,"wins":0}); d["graded"]+=1; d["wins"]+=1 if out==1 else 0
        log.debug("üìä Tip outcome: %s -> %s (market: %s)", sugg, "WIN" if out==1 else "LOSS", mkt)
    
    log.debug("üìä Summary: total=%s, graded=%s, wins=%s", total, graded, wins)
    
    if graded==0:
        msg="üìä Daily Digest\nNo graded tips for yesterday."
        log.info("üìä No graded tips for digest")
    else:
        acc=100.0*wins/max(1,graded)
        lines=[f"üìä <b>Daily Digest</b> (yesterday, Berlin time)",
               f"Tips sent: {total}  ‚Ä¢  Graded: {graded}  ‚Ä¢  Wins: {wins}  ‚Ä¢  Accuracy: {acc:.1f}%"]
        
        log.info("üìä Digest accuracy: %.1f%% (%s/%s)", acc, wins, graded)
        
        for mk,st in sorted(by.items()):
            if st["graded"]==0: continue
            a=100.0*st["wins"]/st["graded"]; 
            lines.append(f"‚Ä¢ {escape(mk)} ‚Äî {st['wins']}/{st['graded']} ({a:.1f}%)")
            log.debug("üìä Market %s: %s/%s (%.1f%%)", mk, st['wins'], st['graded'], a)
        
        msg="\n".join(lines)
    
    send_telegram(msg); 
    log.info("‚úÖ Daily digest sent to Telegram")
    return msg

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Thresholds & formatting ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _get_market_threshold_key(m: str) -> str: 
    key = f"conf_threshold:{m}"
    log.debug("‚öôÔ∏è Market threshold key: %s", key)
    return key

def _get_market_threshold(m: str) -> float:
    try:
        key = _get_market_threshold_key(m)
        v=get_setting_cached(key)
        if v is not None:
            result = float(v)
            log.debug("‚öôÔ∏è Market threshold for '%s': %s (from DB)", m, result)
            return result
        else:
            result = float(CONF_THRESHOLD)
            log.debug("‚öôÔ∏è Market threshold for '%s': %s (default)", m, result)
            return result
    except Exception as e:
        log.error("‚ùå Error getting market threshold for '%s': %s, using default %s", m, e, CONF_THRESHOLD)
        return float(CONF_THRESHOLD)

def _get_market_threshold_pre(m: str) -> float: 
    result = _get_market_threshold(f"PRE {m}")
    log.debug("‚öôÔ∏è Prematch threshold for '%s': %s", m, result)
    return result

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Scan (in-play) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _candidate_is_sane(sug: str, feat: Dict[str,float]) -> bool:
    log.debug("üß† Checking if candidate is sane: %s", sug)
    gh=int(feat.get("goals_h",0)); ga=int(feat.get("goals_a",0)); total=gh+ga
    
    if sug.startswith("Over"):
        ln=_parse_ou_line_from_suggestion(sug)
        if ln is None: 
            log.debug("üß† Could not parse line from Over suggestion")
            return False
        if total > ln - 1e-9: 
            log.debug("üß† Over %s not sane: total %s already exceeds line", ln, total)
            return False
        log.debug("üß† Over %s is sane: total %s <= line", ln, total)
    
    if sug.startswith("Under"):
        ln=_parse_ou_line_from_suggestion(sug)
        if ln is None: 
            log.debug("üß† Could not parse line from Under suggestion")
            return False
        if total >= ln - 1e-9: 
            log.debug("üß† Under %s not sane: total %s already at or above line", ln, total)
            return False
        log.debug("üß† Under %s is sane: total %s < line", ln, total)
    
    if sug.startswith("BTTS") and (gh>0 and ga>0): 
        log.debug("üß† BTTS not sane: both teams have already scored")
        return False
    
    log.debug("‚úÖ Candidate is sane: %s", sug)
    return True

def production_scan() -> Tuple[int,int]:
    log.info("üöÄ Starting production scan")
    start_time = time.time()
    
    matches=fetch_live_matches(); live_seen=len(matches)
    log.info("üìà Live matches found: %s", live_seen)
    
    if live_seen==0: 
        log.info("‚úÖ Production scan complete: no live matches")
        return 0,0
    
    saved=0; now_ts=int(time.time())
    with db_conn() as c:
        for i, m in enumerate(matches):
            try:
                log.debug("üîç Processing match %s/%s", i+1, len(matches))
                fid=int((m.get("fixture",{}) or {}).get("id") or 0)
                if not fid: 
                    log.debug("‚è≠Ô∏è Skipping match without fixture ID")
                    continue
                
                log.debug("üéØ Processing fixture %s", fid)
                
                if DUP_COOLDOWN_MIN>0:
                    cutoff=now_ts - DUP_COOLDOWN_MIN*60
                    if c.execute("SELECT 1 FROM tips WHERE match_id=%s AND created_ts>=%s LIMIT 1",(fid,cutoff)).fetchone(): 
                        log.debug("‚è≠Ô∏è Skipping duplicate match %s (within cooldown)", fid)
                        continue
                
                feat=extract_features(m); minute=int(feat.get("minute",0))
                log.debug("üìä Match features extracted: minute %s", minute)
                
                if not stats_coverage_ok(feat, minute): 
                    log.debug("‚è≠Ô∏è Skipping due to insufficient stats coverage")
                    continue
                
                if minute < TIP_MIN_MINUTE: 
                    log.debug("‚è≠Ô∏è Skipping: minute %s < minimum %s", minute, TIP_MIN_MINUTE)
                    continue
                
                if HARVEST_MODE and minute>=TRAIN_MIN_MINUTE and minute%3==0:
                    try: 
                        save_snapshot_from_match(m, feat)
                        log.debug("üì∏ Harvest snapshot saved")
                    except Exception as e:
                        log.error("‚ùå Failed to save snapshot: %s", e)

                league_id, league=_league_name(m); home,away=_teams(m); score=_pretty_score(m)
                log.debug("üèÜ %s vs %s (%s) - %s", home, away, league, score)
                
                candidates: List[Tuple[str,str,float]]=[]

                # OU predictions
                log.debug("üéØ Running OU predictions")
                for line in OU_LINES:
                    mdl=_load_ou_model_for_line(line)
                    if not mdl: 
                        log.debug("‚è≠Ô∏è No OU model for line %s", line)
                        continue
                    
                    p_over=_score_prob(feat, mdl)
                    mk=f"Over/Under {_fmt_line(line)}"; thr=_get_market_threshold(mk)
                    
                    if p_over*100.0 >= thr and _candidate_is_sane(f"Over {_fmt_line(line)} Goals", feat):
                        candidates.append((mk, f"Over {_fmt_line(line)} Goals", p_over))
                        log.debug("‚úÖ Over %s candidate: prob=%.1f%%, threshold=%.1f%%", line, p_over*100, thr)
                    
                    p_under=1.0-p_over
                    if p_under*100.0 >= thr and _candidate_is_sane(f"Under {_fmt_line(line)} Goals", feat):
                        candidates.append((mk, f"Under {_fmt_line(line)} Goals", p_under))
                        log.debug("‚úÖ Under %s candidate: prob=%.1f%%, threshold=%.1f%%", line, p_under*100, thr)

                # BTTS predictions
                log.debug("üéØ Running BTTS predictions")
                mdl_btts=load_model_from_settings("BTTS_YES")
                if mdl_btts:
                    p=_score_prob(feat, mdl_btts); thr=_get_market_threshold("BTTS")
                    if p*100.0>=thr and _candidate_is_sane("BTTS: Yes", feat): 
                        candidates.append(("BTTS","BTTS: Yes",p))
                        log.debug("‚úÖ BTTS: Yes candidate: prob=%.1f%%, threshold=%.1f%%", p*100, thr)
                    
                    q=1.0-p
                    if q*100.0>=thr and _candidate_is_sane("BTTS: No", feat):  
                        candidates.append(("BTTS","BTTS: No",q))
                        log.debug("‚úÖ BTTS: No candidate: prob=%.1f%%, threshold=%.1f%%", q*100, thr)

                # 1X2 predictions (no draw)
                log.debug("üéØ Running 1X2 predictions")
                mh,md,ma=_load_wld_models()
                if mh and md and ma:
                    ph=_score_prob(feat,mh); pd=_score_prob(feat,md); pa=_score_prob(feat,ma)
                    s=max(EPS,ph+pd+pa); ph,pa=ph/s,pa/s
                    thr=_get_market_threshold("1X2")
                    
                    if ph*100.0>=thr: 
                        candidates.append(("1X2","Home Win",ph))
                        log.debug("‚úÖ Home Win candidate: prob=%.1f%%, threshold=%.1f%%", ph*100, thr)
                    
                    if pa*100.0>=thr: 
                        candidates.append(("1X2","Away Win",pa))
                        log.debug("‚úÖ Away Win candidate: prob=%.1f%%, threshold=%.1f%%", pa*100, thr)

                candidates.sort(key=lambda x:x[2], reverse=True)
                log.debug("üìä Candidates found: %s", [(c[1], round(c[2]*100,1)) for c in candidates])
                
                per_match=0; base_now=int(time.time())
                for idx,(market_txt,suggestion,prob) in enumerate(candidates):
                    if suggestion not in ALLOWED_SUGGESTIONS: 
                        log.debug("‚è≠Ô∏è Skipping non-allowed suggestion: %s", suggestion)
                        continue
                    
                    if per_match >= max(1,PREDICTIONS_PER_MATCH): 
                        log.debug("‚è≠Ô∏è Max predictions per match reached: %s", PREDICTIONS_PER_MATCH)
                        break

                    # Odds/EV gate
                    log.debug("üí∞ Applying price/EV gate for: %s", suggestion)
                    pass_odds, odds, book, _ = _price_gate(market_txt, suggestion, fid)
                    if not pass_odds: 
                        log.debug("‚è≠Ô∏è Failed price gate for: %s", suggestion)
                        continue
                    
                    # Complete EV calculation flow
                    ev_pct=None
                    if odds is not None:
                        edge=_ev(prob, odds)  # decimal (e.g. 0.05)
                        ev_pct=round(edge*100.0,1)
                        ev_bps = int(round(edge*10000))
                        if ev_bps < EDGE_MIN_BPS:  # basis points compare
                            log.debug("‚è≠Ô∏è EV too low: %s bps < minimum %s bps", ev_bps, EDGE_MIN_BPS)
                            continue
                        log.debug("‚úÖ EV passed: %s bps >= minimum %s bps", ev_bps, EDGE_MIN_BPS)

                    created_ts=base_now+idx
                    raw=float(prob); prob_pct=round(raw*100.0,1)
                    
                    log.debug("üíæ Saving tip to database: %s @ %.1f%%", suggestion, prob_pct)
                    
                    # PATCH: reuse the existing connection `c`
                    c.execute(
                        "INSERT INTO tips(match_id,league_id,league,home,away,market,suggestion,confidence,confidence_raw,score_at_tip,minute,created_ts,odds,book,ev_pct,sent_ok) "
                        "VALUES(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,0)",
                        (fid,league_id,league,home,away,market_txt,suggestion,float(prob_pct),raw,score,minute,created_ts,
                         (float(odds) if odds is not None else None), (book or None), (float(ev_pct) if ev_pct is not None else None))
                    )

                    log.debug("üì± Sending tip to Telegram")
                    sent=_send_tip(home,away,league,minute,score,suggestion,float(prob_pct),feat,odds,book,ev_pct)
                    if sent:
                        c.execute("UPDATE tips SET sent_ok=1 WHERE match_id=%s AND created_ts=%s",(fid,created_ts))
                        log.debug("‚úÖ Tip sent successfully")
                    else:
                        log.warning("‚ö†Ô∏è Failed to send tip to Telegram")

                    saved+=1; per_match+=1
                    log.info("‚úÖ Tip saved: %s vs %s - %s @ %.1f%%", home, away, suggestion, prob_pct)
                    
                    if MAX_TIPS_PER_SCAN and saved>=MAX_TIPS_PER_SCAN: 
                        log.info("‚èπÔ∏è Max tips per scan reached: %s", MAX_TIPS_PER_SCAN)
                        break
                
                if MAX_TIPS_PER_SCAN and saved>=MAX_TIPS_PER_SCAN: 
                    log.info("‚èπÔ∏è Stopping scan after reaching max tips")
                    break
                    
            except Exception as e:
                log.exception("‚ùå Error processing match: %s", e)
                continue
    
    elapsed = time.time() - start_time
    log.info("‚úÖ Production scan completed in %.2f seconds: saved=%d, live_seen=%d", elapsed, saved, live_seen)
    return saved, live_seen

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Prematch (compact: save-only, thresholds respected) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def extract_prematch_features(fx: dict) -> Dict[str,float]:
    """Extract prematch features with better error handling"""
    log.debug("üìä Extracting prematch features")
    
    try:
        teams=fx.get("teams") or {}; th=(teams.get("home") or {}).get("id"); ta=(teams.get("away") or {}).get("id")
        if not th or not ta: 
            log.debug("‚ùå Missing team IDs for prematch features")
            return {}
        
        def _rate(games):
            ov25=ov35=btts=played=0
            for g in games:
                st=(((g.get("fixture") or {}).get("status") or {}).get("short") or "").upper()
                if st not in {"FT","AET","PEN"}: continue
                gh=int((g.get("goals") or {}).get("home") or 0); ga=int((g.get("goals") or {}).get("away") or 0)
                played+=1; 
                if gh+ga>2: ov25+=1
                if gh+ga>3: ov35+=1
                if gh>0 and ga>0: btts+=1
            if played==0: 
                log.debug("üìä No played games in sample")
                return 0,0,0
            log.debug("üìä Rate calculation: played=%s, ov25=%s, ov35=%s, btts=%s", played, ov25, ov35, btts)
            return ov25/played, ov35/played, btts/played
        
        log.debug("üìä Fetching past fixtures for teams")
        last_h=_api_last_fixtures(th,5); last_a=_api_last_fixtures(ta,5); h2h=_api_h2h(th,ta,5)
        
        ov25_h,ov35_h,btts_h=_rate(last_h); ov25_a,ov35_a,btts_a=_rate(last_a); ov25_h2h,ov35_h2h,btts_h2h=_rate(h2h)
        
        features = {
            "pm_ov25_h":ov25_h,"pm_ov35_h":ov35_h,"pm_btts_h":btts_h,
            "pm_ov25_a":ov25_a,"pm_ov35_a":ov35_a,"pm_btts_a":btts_a,
            "pm_ov25_h2h":ov25_h2h,"pm_ov35_h2h":ov35_h2h,"pm_btts_h2h":btts_h2h,
            "minute":0.0,"goals_h":0.0,"goals_a":0.0,"goals_sum":0.0,"goals_diff":0.0,
            "xg_h":0.0,"xg_a":0.0,"xg_sum":0.0,"xg_diff":0.0,"sot_h":0.0,"sot_a":0.0,"sot_sum":0.0,
            "cor_h":0.0,"cor_a":0.0,"cor_sum":0.0,"pos_h":0.0,"pos_a":0.0,"pos_diff":0.0,
            "red_h":0.0,"red_a":0.0,"red_sum":0.0
        }
        
        log.debug("‚úÖ Prematch features extracted: %s", {k: round(v, 2) for k, v in features.items()})
        return features
    except Exception as e:
        log.error("‚ùå Error extracting prematch features: %s", e)
        return {}

def _kickoff_berlin(utc_iso: str|None) -> str:
    try:
        if not utc_iso: 
            log.debug("‚è∞ No UTC time provided")
            return "TBD"
        dt=datetime.fromisoformat(utc_iso.replace("Z","+00:00"))
        result = dt.astimezone(BERLIN_TZ).strftime("%H:%M")
        log.debug("‚è∞ Converted UTC %s to Berlin %s", utc_iso, result)
        return result
    except Exception as e:
        log.debug("‚è∞ Failed to parse time '%s': %s", utc_iso, e)
        return "TBD"

def _format_motd_message(home, away, league, kickoff_txt, suggestion, prob_pct, odds=None, book=None, ev_pct=None):
    log.debug("‚úçÔ∏è Formatting MOTD message")
    money = ""
    if odds:
        if ev_pct is not None:
            money = f"\nüí∞ <b>Odds:</b> {odds:.2f} @ {book or 'Book'}  ‚Ä¢  <b>EV:</b> {ev_pct:+.1f}%"
        else:
            money = f"\nüí∞ <b>Odds:</b> {odds:.2f} @ {book or 'Book'}"
    
    message = (
        "üèÖ <b>Match of the Day</b>\n"
        f"<b>Match:</b> {escape(home)} vs {escape(away)}\n"
        f"üèÜ <b>League:</b> {escape(league)}\n"
        f"‚è∞ <b>Kickoff (Berlin):</b> {kickoff_txt}\n"
        f"<b>Tip:</b> {escape(suggestion)}\n"
        f"üìà <b>Confidence:</b> {prob_pct:.1f}%{money}"
    )
    
    log.debug("‚úÖ MOTD message formatted (length: %s chars)", len(message))
    return message

def prematch_scan_save() -> int:
    log.info("üåÖ Starting prematch scan")
    start_time = time.time()
    
    fixtures=_collect_todays_prematch_fixtures(); 
    log.info("üìÖ Found %s prematch fixtures", len(fixtures))
    
    if not fixtures: 
        log.info("‚úÖ Prematch scan complete: no fixtures")
        return 0
    
    saved=0
    for i, fx in enumerate(fixtures):
        try:
            log.debug("üîç Processing prematch fixture %s/%s", i+1, len(fixtures))
            fixture=fx.get("fixture") or {}; lg=fx.get("league") or {}; teams=fx.get("teams") or {}
            home=(teams.get("home") or {}).get("name",""); away=(teams.get("away") or {}).get("name","")
            league_id=int((lg.get("id") or 0)); league=f"{lg.get('country','')} - {lg.get('name','')}".strip(" -"); fid=int((fixture.get("id") or 0))
            
            log.debug("üèÜ %s vs %s (%s)", home, away, league)
            
            feat=extract_prematch_features(fx); 
            if not fid or not feat: 
                log.debug("‚è≠Ô∏è Skipping fixture without features")
                continue
            
            candidates: List[Tuple[str,str,float]]=[]
            
            # PRE OU via PRE_OU_* models
            log.debug("üéØ Running prematch OU predictions")
            for line in OU_LINES:
                mdl=load_model_from_settings(f"PRE_OU_{_fmt_line(line)}")
                if not mdl: 
                    log.debug("‚è≠Ô∏è No prematch OU model for line %s", line)
                    continue
                
                p=_score_prob(feat, mdl); mk=f"Over/Under {_fmt_line(line)}"; thr=_get_market_threshold_pre(mk)
                
                if p*100.0>=thr:   
                    candidates.append((f"PRE {mk}", f"Over {_fmt_line(line)} Goals", p))
                    log.debug("‚úÖ Prematch Over %s candidate: prob=%.1f%%, threshold=%.1f%%", line, p*100, thr)
                
                q=1.0-p
                if q*100.0>=thr:   
                    candidates.append((f"PRE {mk}", f"Under {_fmt_line(line)} Goals", q))
                    log.debug("‚úÖ Prematch Under %s candidate: prob=%.1f%%, threshold=%.1f%%", line, q*100, thr)
            
            # PRE BTTS
            log.debug("üéØ Running prematch BTTS predictions")
            mdl=load_model_from_settings("PRE_BTTS_YES")
            if mdl:
                p=_score_prob(feat, mdl); thr=_get_market_threshold_pre("BTTS")
                if p*100.0>=thr: 
                    candidates.append(("PRE BTTS","BTTS: Yes",p))
                    log.debug("‚úÖ Prematch BTTS: Yes candidate: prob=%.1f%%, threshold=%.1f%%", p*100, thr)
                
                q=1.0-p
                if q*100.0>=thr: 
                    candidates.append(("PRE BTTS","BTTS: No",q))
                    log.debug("‚úÖ Prematch BTTS: No candidate: prob=%.1f%%, threshold=%.1f%%", q*100, thr)
            
            # PRE 1X2 (draw suppressed)
            log.debug("üéØ Running prematch 1X2 predictions")
            mh,ma=load_model_from_settings("PRE_WLD_HOME"), load_model_from_settings("PRE_WLD_AWAY")
            if mh and ma:
                ph=_score_prob(feat,mh); pa=_score_prob(feat,ma); s=max(EPS,ph+pa); ph,pa=ph/s,pa/s
                thr=_get_market_threshold_pre("1X2")
                
                if ph*100.0>=thr: 
                    candidates.append(("PRE 1X2","Home Win",ph))
                    log.debug("‚úÖ Prematch Home Win candidate: prob=%.1f%%, threshold=%.1f%%", ph*100, thr)
                
                if pa*100.0>=thr: 
                    candidates.append(("PRE 1X2","Away Win",pa))
                    log.debug("‚úÖ Prematch Away Win candidate: prob=%.1f%%, threshold=%.1f%%", pa*100, thr)
            
            if not candidates: 
                log.debug("‚è≠Ô∏è No candidates for this fixture")
                continue
            
            candidates.sort(key=lambda x:x[2], reverse=True)
            log.debug("üìä Prematch candidates found: %s", [(c[1], round(c[2]*100,1)) for c in candidates])
            
            base_now=int(time.time()); per_match=0
            for idx,(mk,sug,prob) in enumerate(candidates):
                if sug not in ALLOWED_SUGGESTIONS: 
                    log.debug("‚è≠Ô∏è Skipping non-allowed suggestion: %s", sug)
                    continue
                
                if per_match>=max(1,PREDICTIONS_PER_MATCH): 
                    log.debug("‚è≠Ô∏è Max predictions per match reached: %s", PREDICTIONS_PER_MATCH)
                    break
                
                # Odds/EV gate
                log.debug("üí∞ Applying price/EV gate for prematch: %s", sug)
                pass_odds, odds, book, _ = _price_gate(mk.replace("PRE ",""), sug, fid)
                if not pass_odds: 
                    log.debug("‚è≠Ô∏è Failed price gate for prematch: %s", sug)
                    continue
                
                ev_pct=None
                if odds is not None:
                    edge=_ev(prob, odds); ev_pct=round(edge*100.0,1)
                    ev_bps = int(round(edge*10000))
                    if ev_bps < EDGE_MIN_BPS: 
                        log.debug("‚è≠Ô∏è EV too low for prematch: %s bps < minimum %s bps", ev_bps, EDGE_MIN_BPS)
                        continue
                    log.debug("‚úÖ Prematch EV passed: %s bps >= minimum %s bps", ev_bps, EDGE_MIN_BPS)
                
                created_ts=base_now+idx; raw=float(prob); pct=round(raw*100.0,1)
                
                log.debug("üíæ Saving prematch tip to database: %s @ %.1f%%", sug, pct)
                with db_conn() as c2:
                    c2.execute("INSERT INTO tips(match_id,league_id,league,home,away,market,suggestion,confidence,confidence_raw,score_at_tip,minute,created_ts,odds,book,ev_pct,sent_ok) "
                               "VALUES(%s,%s,%s,%s,%s,%s,%s,%s,%s,'0-0',0,%s,%s,%s,%s,0)",
                               (fid,league_id,league,home,away,mk,sug,float(pct),raw,created_ts,
                                (float(odds) if odds is not None else None), (book or None), (float(ev_pct) if ev_pct is not None else None)))
                
                saved+=1; per_match+=1
                log.info("‚úÖ Prematch tip saved: %s vs %s - %s @ %.1f%%", home, away, sug, pct)
        
        except Exception as e:
            log.exception("‚ùå Error processing prematch fixture: %s", e)
            continue
    
    elapsed = time.time() - start_time
    log.info("‚úÖ Prematch scan completed in %.2f seconds: saved=%d", elapsed, saved)
    return saved

# Optional min EV for MOTD (basis points, e.g. 300 = +3.00%). 0 disables EV gate.
MOTD_MIN_EV_BPS = int(os.getenv("MOTD_MIN_EV_BPS", "0"))
log.info("üèÖ MOTD minimum EV: %s bps", MOTD_MIN_EV_BPS)

def send_match_of_the_day() -> bool:
    """Pick the single best prematch tip for today (PRE_* models). Sends to Telegram."""
    log.info("üèÖ Starting Match of the Day selection")
    
    fixtures = _collect_todays_prematch_fixtures()
    if not fixtures:
        log.info("üèÖ No fixtures found for today")
        return send_telegram("üèÖ Match of the Day: no eligible fixtures today.")

    # Optional league allow-list just for MOTD
    if MOTD_LEAGUE_IDS:
        log.info("üèÖ Filtering fixtures by league IDs: %s", MOTD_LEAGUE_IDS)
        fixtures = [
            f for f in fixtures
            if int(((f.get("league") or {}).get("id") or 0)) in MOTD_LEAGUE_IDS
        ]
        log.info("üèÖ After league filtering: %s fixtures", len(fixtures))
        
        if not fixtures:
            log.info("üèÖ No fixtures in configured leagues")
            return send_telegram("üèÖ Match of the Day: no fixtures in configured leagues.")

    best = None  # (prob_pct, suggestion, home, away, league, kickoff_txt, odds, book, ev_pct)
    log.debug("üèÖ Evaluating %s fixtures for MOTD", len(fixtures))

    for i, fx in enumerate(fixtures):
        log.debug("üèÖ Processing fixture %s/%s for MOTD", i+1, len(fixtures))
        fixture = fx.get("fixture") or {}
        lg      = fx.get("league") or {}
        teams   = fx.get("teams") or {}
        fid     = int((fixture.get("id") or 0))

        home = (teams.get("home") or {}).get("name","")
        away = (teams.get("away") or {}).get("name","")
        league = f"{lg.get('country','')} - {lg.get('name','')}".strip(" -")
        kickoff_txt = _kickoff_berlin((fixture.get("date") or ""))

        log.debug("üèÖ Evaluating: %s vs %s (%s)", home, away, league)

        feat = extract_prematch_features(fx)
        if not feat:
            log.debug("‚è≠Ô∏è No features for %s vs %s", home, away)
            continue

        # Collect PRE candidates (same thresholds as prematch_scan_save)
        candidates: List[Tuple[str,str,float]] = []

        for line in OU_LINES:
            mdl = load_model_from_settings(f"PRE_OU_{_fmt_line(line)}")
            if not mdl: continue
            p = _score_prob(feat, mdl)
            mk = f"Over/Under {_fmt_line(line)}"
            thr = _get_market_threshold_pre(mk)
            if p*100.0 >= thr:   candidates.append((mk, f"Over {_fmt_line(line)} Goals", p))
            q = 1.0 - p
            if q*100.0 >= thr:   candidates.append((mk, f"Under {_fmt_line(line)} Goals", q))

        mdl = load_model_from_settings("PRE_BTTS_YES")
        if mdl:
            p = _score_prob(feat, mdl); thr = _get_market_threshold_pre("BTTS")
            if p*100.0 >= thr: candidates.append(("BTTS","BTTS: Yes", p))
            q = 1.0 - p
            if q*100.0 >= thr: candidates.append(("BTTS","BTTS: No",  q))

        mh = load_model_from_settings("PRE_WLD_HOME")
        ma = load_model_from_settings("PRE_WLD_AWAY")
        if mh and ma:
            ph = _score_prob(feat, mh); pa = _score_prob(feat, ma)
            s = max(EPS, ph+pa); ph, pa = ph/s, pa/s
            thr = _get_market_threshold_pre("1X2")
            if ph*100.0 >= thr: candidates.append(("1X2","Home Win", ph))
            if pa*100.0 >= thr: candidates.append(("1X2","Away Win", pa))

        if not candidates:
            log.debug("‚è≠Ô∏è No candidates for %s vs %s", home, away)
            continue

        # Take the single best for this fixture (by probability) then apply odds/EV gate
        candidates.sort(key=lambda x: x[2], reverse=True)
        mk, sug, prob = candidates[0]
        prob_pct = prob * 100.0
        
        log.debug("üèÖ Best candidate for %s vs %s: %s @ %.1f%%", home, away, sug, prob_pct)
        
        if prob_pct < MOTD_CONF_MIN:
            log.debug("‚è≠Ô∏è Confidence too low: %.1f%% < minimum %.1f%%", prob_pct, MOTD_CONF_MIN)
            continue

        # Odds/EV (reuse in-play price gate; market text must be without "PRE ")
        pass_odds, odds, book, _ = _price_gate(mk, sug, fid)
        if not pass_odds:
            log.debug("‚è≠Ô∏è Failed price gate for %s", sug)
            continue

        ev_pct = None
        if odds is not None:
            edge = _ev(prob, odds)            # decimal (e.g. 0.05)
            ev_bps = int(round(edge * 10000)) # basis points
            ev_pct = round(edge * 100.0, 1)
            if MOTD_MIN_EV_BPS > 0 and ev_bps < MOTD_MIN_EV_BPS:
                log.debug("‚è≠Ô∏è EV too low: %s bps < minimum %s bps", ev_bps, MOTD_MIN_EV_BPS)
                continue
            log.debug("‚úÖ EV acceptable: %s bps", ev_bps)

        item = (prob_pct, sug, home, away, league, kickoff_txt, odds, book, ev_pct)
        if best is None or prob_pct > best[0]:
            best = item
            log.debug("üèÖ New best candidate: %s @ %.1f%%", sug, prob_pct)

    if not best:
        log.info("üèÖ No suitable MOTD pick found")
        return send_telegram("üèÖ Match of the Day: no prematch pick met thresholds.")
    
    prob_pct, sug, home, away, league, kickoff_txt, odds, book, ev_pct = best
    log.info("üèÖ Selected MOTD: %s vs %s - %s @ %.1f%%", home, away, sug, prob_pct)
    
    return send_telegram(_format_motd_message(home, away, league, kickoff_txt, sug, prob_pct, odds, book, ev_pct))

def auto_train_job():
    log.info("ü§ñ Starting auto-train job")
    if not TRAIN_ENABLE: 
        log.info("‚è≠Ô∏è Training disabled (TRAIN_ENABLE=0)")
        send_telegram("ü§ñ Training skipped: TRAIN_ENABLE=0"); 
        return
    
    send_telegram("ü§ñ Training started.")
    try:
        log.info("ü§ñ Calling train_models function")
        res=train_models() or {}; ok=bool(res.get("ok"))
        if not ok:
            reason=res.get("reason") or res.get("error") or "unknown"
            log.warning("ü§ñ Training failed: %s", reason)
            send_telegram(f"‚ö†Ô∏è Training finished: <b>SKIPPED</b>\nReason: {escape(str(reason))}"); 
            return
        
        trained=[k for k,v in (res.get("trained") or {}).items() if v]
        thr=(res.get("thresholds") or {}); mets=(res.get("metrics") or {})
        
        log.info("ü§ñ Training successful: trained %s models", len(trained))
        lines=["ü§ñ <b>Model training OK</b>"]
        if trained: 
            lines.append("‚Ä¢ Trained: " + ", ".join(sorted(trained)))
            log.debug("ü§ñ Trained models: %s", trained)
        
        if thr: 
            lines.append("‚Ä¢ Thresholds: " + "  |  ".join([f"{escape(k)}: {float(v):.1f}%" for k,v in thr.items()]))
            log.debug("ü§ñ New thresholds: %s", thr)
        
        send_telegram("\n".join(lines))
        log.info("‚úÖ Auto-train job completed successfully")
        
    except Exception as e:
        log.exception("‚ùå Training job failed: %s", e); 
        send_telegram(f"‚ùå Training <b>FAILED</b>\n{escape(str(e))}")

def _pick_threshold(y_true,y_prob,target_precision,min_preds,default_pct):
    log.debug("üéØ Picking optimal threshold")
    import numpy as np
    y=np.asarray(y_true,dtype=int); p=np.asarray(y_prob,dtype=float)
    best=default_pct/100.0
    
    log.debug("üéØ Data: %s samples, target precision: %s, min predictions: %s", len(y), target_precision, min_preds)
    
    for t in np.arange(MIN_THRESH,MAX_THRESH+1e-9,1.0)/100.0:
        pred=(p>=t).astype(int); n=int(pred.sum())
        if n<min_preds: 
            log.debug("üéØ Threshold %.3f: only %s predictions (< %s)", t, n, min_preds)
            continue
        
        tp=int(((pred==1)&(y==1)).sum()); prec=tp/max(1,n)
        log.debug("üéØ Threshold %.3f: %s predictions, %s true positives, precision: %.3f", t, n, tp, prec)
        
        if prec>=target_precision: 
            best=float(t)
            log.debug("üéØ Found threshold %.3f meeting target precision %.3f", best, target_precision)
            break
    
    result = best*100.0
    log.debug("üéØ Selected threshold: %.1f%%", result)
    return result

def auto_tune_thresholds(days: int = 14) -> Dict[str,float]:
    log.info("üîß Starting auto-tune thresholds (last %s days)", days)
    if not AUTO_TUNE_ENABLE: 
        log.info("‚è≠Ô∏è Auto-tune disabled")
        return {}
    
    cutoff=int(time.time())-days*24*3600
    log.debug("üîß Cutoff timestamp: %s (%s days ago)", cutoff, days)
    
    with db_conn() as c:
        rows=c.execute("""
            SELECT t.market, t.suggestion, COALESCE(t.confidence_raw, t.confidence/100.0) prob,
                   r.final_goals_h, r.final_goals_a, r.btts_yes
            FROM tips t JOIN match_results r ON r.match_id=t.match_id
            WHERE t.created_ts >= %s AND t.suggestion<>'HARVEST' AND t.sent_ok=1
        """,(cutoff,)).fetchall()
    
    log.debug("üîß Found %s tips for threshold tuning", len(rows))
    
    by={}
    for (mk,sugg,prob,gh,ga,btts) in rows:
        out=_tip_outcome_for_result(sugg, {"final_goals_h":gh,"final_goals_a":ga,"btts_yes":btts})
        if out is None: 
            log.debug("üîß Tip not gradable: %s", sugg)
            continue
        
        by.setdefault(mk, []).append((float(prob), int(out)))
    
    log.debug("üîß Graded tips by market: %s", {k: len(v) for k, v in by.items()})
    
    tuned={}
    for mk,arr in by.items():
        if len(arr)<THRESH_MIN_PREDICTIONS: 
            log.debug("üîß Market '%s': insufficient data (%s < %s)", mk, len(arr), THRESH_MIN_PREDICTIONS)
            continue
        
        probs=[p for (p,_) in arr]; wins=[y for (_,y) in arr]
        pct=_pick_threshold(wins, probs, TARGET_PRECISION, THRESH_MIN_PREDICTIONS, CONF_THRESHOLD)
        
        log.info("üîß Tuning market '%s': new threshold %.1f%% (from %s samples)", mk, pct, len(arr))
        
        set_setting(f"conf_threshold:{mk}", f"{pct:.2f}"); 
        _SETTINGS_CACHE.invalidate(f"conf_threshold:{mk}"); 
        tuned[mk]=pct
    
    if tuned:
        log.info("‚úÖ Auto-tune updated %s thresholds", len(tuned))
        send_telegram("üîß Auto-tune updated thresholds:\n" + "\n".join([f"‚Ä¢ {k}: {v:.1f}%" for k,v in tuned.items()]))
    else: 
        log.info("‚ÑπÔ∏è Auto-tune: no updates (insufficient data)")
        send_telegram("üîß Auto-tune: no updates (insufficient data).")
    
    return tuned

def retry_unsent_tips(minutes: int = 30, limit: int = 200) -> int:
    log.info("üîÑ Retrying unsent tips (last %s minutes, limit %s)", minutes, limit)
    cutoff = int(time.time()) - minutes*60
    retried = 0
    
    with db_conn() as c:
        rows = c.execute(
            "SELECT match_id,league,home,away,market,suggestion,confidence,confidence_raw,score_at_tip,minute,created_ts,odds,book,ev_pct "
            "FROM tips WHERE sent_ok=0 AND created_ts >= %s ORDER BY created_ts ASC LIMIT %s",
            (cutoff, limit)
        ).fetchall()

        log.debug("üîÑ Found %s unsent tips to retry", len(rows))
        
        for (mid, league, home, away, market, sugg, conf, conf_raw, score, minute, cts, odds, book, ev_pct) in rows:
            log.debug("üîÑ Retrying tip: %s vs %s - %s", home, away, sugg)
            ok = send_telegram(_format_tip_message(home, away, league, int(minute), score, sugg, float(conf), {}, odds, book, ev_pct))
            if ok:
                c.execute("UPDATE tips SET sent_ok=1 WHERE match_id=%s AND created_ts=%s", (mid, cts))
                retried += 1
                log.debug("‚úÖ Successfully resent tip for %s vs %s", home, away)
            else:
                log.warning("‚ö†Ô∏è Failed to resend tip for %s vs %s", home, away)
    
    if retried:
        log.info("‚úÖ Retry completed: %s tips resent", retried)
    else:
        log.info("‚ÑπÔ∏è No tips needed retrying")
    return retried

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Scheduler ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _run_with_pg_lock(lock_key: int, fn, *a, **k):
    log.debug("üîí Attempting to acquire lock %s for function %s", lock_key, fn.__name__)
    try:
        with db_conn() as c:
            got=c.execute("SELECT pg_try_advisory_lock(%s)",(lock_key,)).fetchone()[0]
            if not got: 
                log.info("üîí Lock %s busy; skipped %s.", lock_key, fn.__name__)
                return None
            
            log.debug("üîí Lock %s acquired for %s", lock_key, fn.__name__)
            try: 
                result = fn(*a,**k)
                log.debug("üîí Function %s completed with lock %s", fn.__name__, lock_key)
                return result
            finally: 
                c.execute("SELECT pg_advisory_unlock(%s)",(lock_key,))
                log.debug("üîí Lock %s released", lock_key)
    except Exception as e:
        log.exception("üîí Lock %s failed for %s: %s", lock_key, fn.__name__, e)
        return None

_scheduler_started=False
def _start_scheduler_once():
    global _scheduler_started
    if _scheduler_started or not RUN_SCHEDULER: 
        log.info("‚è≠Ô∏è Scheduler already started or disabled")
        return
    
    try:
        log.info("‚è∞ Starting scheduler")
        sched=BackgroundScheduler(timezone=TZ_UTC)
        
        # Production scan job
        sched.add_job(
            lambda:_run_with_pg_lock(1001,production_scan),
            "interval",
            seconds=SCAN_INTERVAL_SEC,
            id="scan",
            max_instances=1,
            coalesce=True
        )
        log.info("‚è∞ Scheduled scan job every %s seconds", SCAN_INTERVAL_SEC)
        
        # Backfill job
        sched.add_job(
            lambda:_run_with_pg_lock(1002,backfill_results_for_open_matches,400),
            "interval",
            minutes=BACKFILL_EVERY_MIN,
            id="backfill",
            max_instances=1,
            coalesce=True
        )
        log.info("‚è∞ Scheduled backfill job every %s minutes", BACKFILL_EVERY_MIN)
        
        # Daily accuracy digest
        if DAILY_ACCURACY_DIGEST_ENABLE:
            sched.add_job(
                lambda:_run_with_pg_lock(1003,daily_accuracy_digest),
                CronTrigger(hour=DAILY_ACCURACY_HOUR, minute=DAILY_ACCURACY_MINUTE, timezone=BERLIN_TZ),
                id="digest", 
                max_instances=1, 
                coalesce=True
            )
            log.info("‚è∞ Scheduled daily digest at %02d:%02d Berlin time", DAILY_ACCURACY_HOUR, DAILY_ACCURACY_MINUTE)
        
        # MOTD job
        if MOTD_PREDICT:
            sched.add_job(
                lambda:_run_with_pg_lock(1004,send_match_of_the_day),
                CronTrigger(hour=int(os.getenv("MOTD_HOUR","19")), minute=int(os.getenv("MOTD_MINUTE","15")), timezone=BERLIN_TZ),
                id="motd", 
                max_instances=1, 
                coalesce=True
            )
            log.info("‚è∞ Scheduled MOTD at %02d:%02d Berlin time", int(os.getenv("MOTD_HOUR","19")), int(os.getenv("MOTD_MINUTE","15")))
        
        # Training job
        if TRAIN_ENABLE:
            sched.add_job(
                lambda:_run_with_pg_lock(1005,auto_train_job),
                CronTrigger(hour=TRAIN_HOUR_UTC, minute=TRAIN_MINUTE_UTC, timezone=TZ_UTC),
                id="train", 
                max_instances=1, 
                coalesce=True
            )
            log.info("‚è∞ Scheduled training at %02d:%02d UTC", TRAIN_HOUR_UTC, TRAIN_MINUTE_UTC)
        
        # Auto-tune job
        if AUTO_TUNE_ENABLE:
            sched.add_job(
                lambda:_run_with_pg_lock(1006,auto_tune_thresholds,14),
                CronTrigger(hour=4, minute=7, timezone=TZ_UTC),
                id="auto_tune", 
                max_instances=1, 
                coalesce=True
            )
            log.info("‚è∞ Scheduled auto-tune at 04:07 UTC")
        
        # Retry unsent tips job
        sched.add_job(
            lambda:_run_with_pg_lock(1007,retry_unsent_tips,30,200),
            "interval",
            minutes=10,
            id="retry",
            max_instances=1,
            coalesce=True
        )
        log.info("‚è∞ Scheduled retry job every 10 minutes")
        
        sched.start(); 
        _scheduler_started=True
        send_telegram("üöÄ goalsniper AI mode (in-play + prematch) started.")
        log.info("‚úÖ Scheduler started with %s jobs", len(sched.get_jobs()))
        
    except Exception as e:
        log.exception("‚ùå Scheduler failed to start: %s", e)

_start_scheduler_once()

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Admin / auth ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _require_admin():
    log.debug("üîí Checking admin authentication")
    key=request.headers.get("X-API-Key") or request.args.get("key") or ((request.json or {}).get("key") if request.is_json else None)
    
    if not ADMIN_API_KEY or key != ADMIN_API_KEY: 
        log.warning("üîí Admin authentication failed for key: %s", key)
        abort(401)
    
    log.debug("‚úÖ Admin authentication successful")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ HTTP endpoints ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
@app.route("/")
def root(): 
    log.info("üåê Root endpoint accessed")
    return jsonify({"ok": True, "name": "goalsniper", "mode": "FULL_AI", "scheduler": RUN_SCHEDULER})

@app.route("/health")
def health():
    log.info("üè• Health check requested")
    try:
        with db_conn() as c:
            n=c.execute("SELECT COUNT(*) FROM tips").fetchone()[0]
        log.info("‚úÖ Health check passed: DB ok, %s tips", n)
        return jsonify({"ok": True, "db": "ok", "tips_count": int(n)})
    except Exception as e:
        log.error("‚ùå Health check failed: %s", e)
        return jsonify({"ok": False, "error": str(e)}), 500

@app.route("/init-db", methods=["POST"])
def http_init_db(): 
    log.info("üóÑÔ∏è Admin requested database initialization")
    _require_admin(); 
    init_db(); 
    log.info("‚úÖ Database initialization completed via HTTP")
    return jsonify({"ok": True})

@app.route("/admin/scan", methods=["POST","GET"])
def http_scan(): 
    log.info("üöÄ Admin requested manual scan")
    _require_admin(); 
    s,l=production_scan(); 
    log.info("‚úÖ Manual scan completed: saved=%s, live_seen=%s", s, l)
    return jsonify({"ok": True, "saved": s, "live_seen": l})

@app.route("/admin/backfill-results", methods=["POST","GET"])
def http_backfill(): 
    log.info("üîÑ Admin requested backfill")
    _require_admin(); 
    n=backfill_results_for_open_matches(400); 
    log.info("‚úÖ Backfill completed: updated=%s", n)
    return jsonify({"ok": True, "updated": n})

@app.route("/admin/train", methods=["POST","GET"])
def http_train():
    log.info("ü§ñ Admin requested manual training")
    _require_admin()
    if not TRAIN_ENABLE: 
        log.warning("‚ö†Ô∏è Training disabled")
        return jsonify({"ok": False, "reason": "training disabled"}), 400
    
    try: 
        out=train_models(); 
        log.info("‚úÖ Manual training completed")
        return jsonify({"ok": True, "result": out})
    except Exception as e:
        log.exception("‚ùå Manual training failed: %s", e)
        return jsonify({"ok": False, "error": str(e)}), 500

@app.route("/admin/train-notify", methods=["POST","GET"])
def http_train_notify(): 
    log.info("ü§ñ Admin requested training notification")
    _require_admin(); 
    auto_train_job(); 
    log.info("‚úÖ Training notification sent")
    return jsonify({"ok": True})

@app.route("/admin/digest", methods=["POST","GET"])
def http_digest(): 
    log.info("üìä Admin requested daily digest")
    _require_admin(); 
    msg=daily_accuracy_digest(); 
    log.info("‚úÖ Daily digest sent: %s", bool(msg))
    return jsonify({"ok": True, "sent": bool(msg)})

@app.route("/admin/auto-tune", methods=["POST","GET"])
def http_auto_tune(): 
    log.info("üîß Admin requested auto-tune")
    _require_admin(); 
    tuned=auto_tune_thresholds(14); 
    log.info("‚úÖ Auto-tune completed: %s thresholds tuned", len(tuned))
    return jsonify({"ok": True, "tuned": tuned})

@app.route("/admin/retry-unsent", methods=["POST","GET"])
def http_retry_unsent(): 
    log.info("üîÑ Admin requested retry unsent")
    _require_admin(); 
    n=retry_unsent_tips(30,200); 
    log.info("‚úÖ Retry unsent completed: %s tips resent", n)
    return jsonify({"ok": True, "resent": n})

@app.route("/admin/prematch-scan", methods=["POST","GET"])
def http_prematch_scan(): 
    log.info("üåÖ Admin requested prematch scan")
    _require_admin(); 
    saved=prematch_scan_save(); 
    log.info("‚úÖ Prematch scan completed: %s tips saved", saved)
    return jsonify({"ok": True, "saved": int(saved)})

@app.route("/admin/motd", methods=["POST","GET"])
def http_motd():
    log.info("üèÖ Admin requested MOTD")
    _require_admin(); 
    ok = send_match_of_the_day(); 
    log.info("‚úÖ MOTD sent: %s", ok)
    return jsonify({"ok": bool(ok)})

@app.route("/settings/<key>", methods=["GET","POST"])
def http_settings(key: str):
    log.info("‚öôÔ∏è Settings endpoint accessed for key: %s", key)
    _require_admin()
    
    if request.method=="GET":
        val=get_setting_cached(key); 
        log.info("‚öôÔ∏è GET setting %s: %s", key, val)
        return jsonify({"ok": True, "key": key, "value": val})
    
    val=(request.get_json(silent=True) or {}).get("value")
    if val is None: 
        log.warning("‚ö†Ô∏è No value provided for setting %s", key)
        abort(400)
    
    log.info("‚öôÔ∏è SET setting %s=%s", key, val)
    set_setting(key, str(val)); 
    _SETTINGS_CACHE.invalidate(key); 
    invalidate_model_caches_for_key(key)
    
    log.info("‚úÖ Setting updated and caches invalidated")
    return jsonify({"ok": True})

@app.route("/tips/latest")
def http_latest():
    limit=int(request.args.get("limit","50"))
    log.info("üìã Latest tips requested (limit: %s)", limit)
    
    with db_conn() as c:
        rows=c.execute("SELECT match_id,league,home,away,market,suggestion,confidence,confidence_raw,score_at_tip,minute,created_ts,odds,book,ev_pct "
                       "FROM tips WHERE suggestion<>'HARVEST' ORDER BY created_ts DESC LIMIT %s",(max(1,min(500,limit)),)).fetchall()
    
    tips=[]
    for r in rows:
        tips.append({
            "match_id":int(r[0]),
            "league":r[1],
            "home":r[2],
            "away":r[3],
            "market":r[4],
            "suggestion":r[5],
            "confidence":float(r[6]),
            "confidence_raw":(float(r[7]) if r[7] is not None else None),
            "score_at_tip":r[8],
            "minute":int(r[9]),
            "created_ts":int(r[10]),
            "odds": (float(r[11]) if r[11] is not None else None), 
            "book": r[12], 
            "ev_pct": (float(r[13]) if r[13] is not None else None)
        })
    
    log.info("‚úÖ Returned %s latest tips", len(tips))
    return jsonify({"ok": True, "tips": tips})

@app.route("/telegram/webhook/<secret>", methods=["POST"])
def telegram_webhook(secret: str):
    log.info("üì± Telegram webhook received")
    if (WEBHOOK_SECRET or "") != secret: 
        log.warning("üîí Telegram webhook secret mismatch")
        abort(403)
    
    update=request.get_json(silent=True) or {}
    log.debug("üì± Webhook update: %s", json.dumps(update)[:200])
    
    try:
        msg=(update.get("message") or {}).get("text") or ""
        log.info("üì± Telegram message: %s", msg)
        
        if msg.startswith("/start"): 
            send_telegram("üëã goalsniper bot (FULL AI mode) is online.")
            log.info("‚úÖ Responded to /start command")
        elif msg.startswith("/digest"): 
            daily_accuracy_digest()
            log.info("‚úÖ Responded to /digest command")
        elif msg.startswith("/motd"): 
            send_match_of_the_day()
            log.info("‚úÖ Responded to /motd command")
        elif msg.startswith("/scan"):
            parts=msg.split()
            if len(parts)>1 and ADMIN_API_KEY and parts[1]==ADMIN_API_KEY:
                s,l=production_scan(); 
                send_telegram(f"üîÅ Scan done. Saved: {s}, Live seen: {l}")
                log.info("‚úÖ Responded to /scan command")
            else: 
                send_telegram("üîí Admin key required.")
                log.warning("‚ö†Ô∏è Unauthorized /scan attempt")
    except Exception as e:
        log.warning("‚ùå Telegram webhook parse error: %s", e)
    
    return jsonify({"ok": True})

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Boot ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _on_boot():
    log.info("üöÄ Starting application boot sequence")
    start_time = time.time()
    
    # Test database connection at startup with proper error messages
    log.info("üîå Testing database connection...")
    try:
        _init_pool()
        log.info("‚úÖ Database connection test successful")
    except Exception as e:
        log.critical("‚ùå Database connection failed: %s", e)
        raise SystemExit(f"Database connection failed: {e}")
    
    init_db(); 
    log.info("‚úÖ Database schema initialized")
    
    set_setting("boot_ts", str(int(time.time())))
    log.info("‚úÖ Boot timestamp set")
    
    elapsed = time.time() - start_time
    log.info("‚úÖ Application boot completed in %.2f seconds", elapsed)

_on_boot()

if __name__ == "__main__":
    host = os.getenv("HOST","0.0.0.0")
    port = int(os.getenv("PORT","8080"))
    log.info("üåç Starting Flask application on %s:%s", host, port)
    app.run(host=host, port=port)
