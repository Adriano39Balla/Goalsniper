import pandas as pd
import numpy as np
import joblib
from datetime import datetime
from pathlib import Path
import sys

# Configure logging first
import logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('training.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score

# Import feature columns from config
try:
    from config import FEATURE_COLUMNS
except ImportError:
    # Define fallback feature columns
    FEATURE_COLUMNS = [
        'home_team_rating', 'away_team_rating', 'home_score', 'away_score',
        'goal_difference', 'total_goals', 'minute', 'time_ratio',
        'league_rank', 'hour_of_day', 'day_of_week', 'month',
        'momentum', 'scoring_pressure', 'home_possession', 'away_possession',
        'home_shots_on_goal', 'away_shots_on_goal', 'implied_prob_home',
        'implied_prob_draw', 'implied_prob_away', 'is_late_game',
        'is_extra_time', 'goals_needed_for_over', 'can_btts_happen'
    ]

def create_calibrated_training_data(n_samples=20000):
    """Create training data with game-state logic"""
    np.random.seed(42)
    
    # Create feature matrix
    X = pd.DataFrame(np.random.randn(n_samples, len(FEATURE_COLUMNS)), columns=FEATURE_COLUMNS)
    
    # Add realistic game-state features
    X['minute'] = np.random.randint(0, 120, n_samples)
    X['home_score'] = np.random.randint(0, 5, n_samples)
    X['away_score'] = np.random.randint(0, 5, n_samples)
    X['total_goals'] = X['home_score'] + X['away_score']
    X['goal_difference'] = X['home_score'] - X['away_score']
    
    # Update derived features
    X['time_ratio'] = X['minute'] / 90.0
    X['is_late_game'] = (X['minute'] > 80).astype(int)
    X['is_extra_time'] = (X['minute'] > 90).astype(int)
    X['goals_needed_for_over'] = np.maximum(0, 3 - X['total_goals'])
    X['can_btts_happen'] = ((X['home_score'] > 0) & (X['away_score'] > 0)).astype(int)
    X['momentum'] = X['goal_difference'] * X['time_ratio']
    X['scoring_pressure'] = X['total_goals'] / np.maximum(X['time_ratio'], 0.1)
    
    # Generate targets with game-state logic
    # Home win: realistic probabilities based on game state
    home_win_base = (
        X['home_team_rating'] * 0.3 +
        X['away_team_rating'] * -0.2 +
        X['home_possession'] * 0.15 +
        X['home_shots_on_goal'] * 0.1
    )
    
    # Apply game-state adjustments
    # Leading late -> higher probability
    leading_late = (X['goal_difference'] > 0) & X['is_late_game']
    home_win_base += leading_late * 0.5
    
    # Drawing late -> lower probability
    drawing_late = (X['goal_difference'] == 0) & X['is_late_game']
    home_win_base -= drawing_late * 0.3
    
    # Losing late -> much lower probability
    losing_late = (X['goal_difference'] < 0) & X['is_late_game']
    home_win_base -= losing_late * 0.7
    
    y_home_win = (home_win_base > 0).astype(int)
    
    # Over 2.5: game-state aware
    over_base = (
        X['scoring_pressure'] * 0.4 +
        X['total_goals'] * 0.3
    )
    
    # Adjust for goals needed and time
    goals_needed_penalty = X['goals_needed_for_over'] * X['is_late_game'] * -0.25
    over_base += goals_needed_penalty
    
    # Already over -> certain
    already_over = (X['total_goals'] >= 3)
    over_base += already_over * 1.0
    
    y_over_25 = (over_base > 0.2).astype(int)
    
    # BTTS: already happened or likely based on game state
    btts_base = (
        X['home_shots_on_goal'] * 0.2 +
        X['away_shots_on_goal'] * 0.2 +
        X['total_goals'] * 0.15
    )
    
    # Already happened -> certain
    already_btts = X['can_btts_happen']
    btts_base += already_btts * 0.8
    
    # Late game without BTTS -> lower probability
    late_no_btts = X['is_late_game'] & (X['can_btts_happen'] == 0)
    btts_base -= late_no_btts * 0.4
    
    y_btts = (btts_base > 0.15).astype(int)
    
    # Add some noise
    y_home_win = (y_home_win + np.random.randn(n_samples) * 0.1 > 0.5).astype(int)
    y_over_25 = (y_over_25 + np.random.randn(n_samples) * 0.1 > 0.5).astype(int)
    y_btts = (y_btts + np.random.randn(n_samples) * 0.1 > 0.5).astype(int)
    
    logger.info(f"Created calibrated training data with {n_samples} samples")
    logger.info(f"Home win: {y_home_win.mean():.2%}")
    logger.info(f"Over 2.5: {y_over_25.mean():.2%}")
    logger.info(f"BTTS: {y_btts.mean():.2%}")
    
    return X, y_home_win, y_over_25, y_btts

def train_calibrated_models():
    """Train calibrated models with game-state awareness"""
    logger.info("=" * 60)
    logger.info("Training CALIBRATED models with game-state logic")
    logger.info(f"Features: {len(FEATURE_COLUMNS)} (including game-state features)")
    logger.info("=" * 60)
    
    # Create training data
    X, y_home_win, y_over_25, y_btts = create_calibrated_training_data(15000)
    
    # Split data
    X_train, X_test, y_home_train, y_home_test = train_test_split(X, y_home_win, test_size=0.2, random_state=42)
    _, _, y_over_train, y_over_test = train_test_split(X, y_over_25, test_size=0.2, random_state=42)
    _, _, y_btts_train, y_btts_test = train_test_split(X, y_btts, test_size=0.2, random_state=42)
    
    models = {}
    scalers = {}
    results = {}
    
    # Train for each target
    targets = [
        ('home_win', y_home_train, y_home_test),
        ('over_2_5', y_over_train, y_over_test),
        ('btts', y_btts_train, y_btts_test)
    ]
    
    for target_name, y_train, y_test in targets:
        logger.info(f"\nüåÄ Training CALIBRATED model for {target_name}")
        
        # Scale features
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Create calibrated Random Forest
        model = RandomForestClassifier(
            n_estimators=250,  # More trees for better calibration
            max_depth=20,  # Deeper trees for complex game-state logic
            min_samples_split=3,
            min_samples_leaf=1,
            max_features='sqrt',
            bootstrap=True,
            n_jobs=-1,
            random_state=42,
            class_weight='balanced'
        )
        
        # Train model
        model.fit(X_train_scaled, y_train)
        
        # Evaluate
        y_pred = model.predict(X_test_scaled)
        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
        
        accuracy = accuracy_score(y_test, y_pred)
        roc_auc = roc_auc_score(y_test, y_pred_proba)
        
        # Calculate precision for different game states
        test_df = X_test.copy()
        test_df['prediction'] = y_pred
        test_df['actual'] = y_test
        
        # Analyze by game time
        early_games = test_df[test_df['minute'] < 60]
        late_games = test_df[test_df['minute'] >= 60]
        
        early_accuracy = accuracy_score(early_games['actual'], early_games['prediction']) if len(early_games) > 0 else 0
        late_accuracy = accuracy_score(late_games['actual'], late_games['prediction']) if len(late_games) > 0 else 0
        
        logger.info(f"üìä Overall Accuracy: {accuracy:.4f}")
        logger.info(f"üìà ROC AUC: {roc_auc:.4f}")
        logger.info(f"‚è∞ Early game (<60') accuracy: {early_accuracy:.4f}")
        logger.info(f"‚è±Ô∏è Late game (‚â•60') accuracy: {late_accuracy:.4f}")
        
        # Feature importance
        feature_importance = dict(zip(FEATURE_COLUMNS, model.feature_importances_))
        top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:8]
        logger.info(f"üéØ Top features: {top_features}")
        
        # Store results
        models[target_name] = model
        scalers[target_name] = scaler
        results[target_name] = {
            'accuracy': accuracy,
            'roc_auc': roc_auc,
            'early_accuracy': early_accuracy,
            'late_accuracy': late_accuracy,
            'feature_importance': feature_importance
        }
    
    # Save calibrated models
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    model_dir = Path(f"models/calibrated_{timestamp}")
    model_dir.mkdir(parents=True, exist_ok=True)
    
    for target, model in models.items():
        model_path = model_dir / f"{target}_calibrated.pkl"
        joblib.dump(model, model_path)
        logger.info(f"üíæ Saved {target} calibrated model")
    
    # Save scalers
    scaler_path = model_dir / "scalers.pkl"
    joblib.dump(scalers, scaler_path)
    
    # Save feature importance
    importance_path = model_dir / "feature_importance.json"
    with open(importance_path, 'w') as f:
        json.dump({k: {kk: float(vv) for kk, vv in v.items()} for k, v in results.items()}, f, indent=2)
    
    # Update current symlink
    current_path = Path("models/current")
    if current_path.exists():
        if current_path.is_symlink():
            current_path.unlink()
        elif current_path.is_dir():
            import shutil
            shutil.rmtree(current_path)
    
    current_path.symlink_to(model_dir)
    
    # Calculate overall performance
    avg_accuracy = np.mean([r['accuracy'] for r in results.values()])
    avg_roc_auc = np.mean([r['roc_auc'] for r in results.values()])
    
    logger.info("=" * 60)
    logger.info("‚úÖ CALIBRATED TRAINING COMPLETE!")
    logger.info(f"üìÅ Models saved to: {model_dir}")
    logger.info(f"üìä Average accuracy: {avg_accuracy:.4f}")
    logger.info(f"üìà Average ROC AUC: {avg_roc_auc:.4f}")
    logger.info("üéØ Features include game-state awareness")
    logger.info("‚öôÔ∏è Models calibrated for late-game scenarios")
    logger.info("=" * 60)
    
    return {
        'success': True,
        'model_dir': str(model_dir),
        'results': results,
        'avg_accuracy': avg_accuracy,
        'avg_roc_auc': avg_roc_auc,
        'timestamp': timestamp
    }

if __name__ == "__main__":
    # Create necessary directories
    Path("models").mkdir(exist_ok=True)
    Path("logs").mkdir(exist_ok=True)
    
    # Train calibrated models
    result = train_calibrated_models()
    
    if result['success']:
        print(f"\n‚úÖ CALIBRATED Training successful!")
        print(f"üìä Average Accuracy: {result['avg_accuracy']:.4f}")
        print(f"üéØ Average ROC AUC: {result['avg_roc_auc']:.4f}")
        print(f"üìÅ Models saved to: {result['model_dir']}")
        print(f"‚öôÔ∏è Features: {len(FEATURE_COLUMNS)} (game-state aware)")
    else:
        print(f"\n‚ùå Training failed")
